<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
    <meta charset="utf-8">
    <meta name="generator" content="quarto-1.8.24">

    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


    <title>ä»£è°¢ç»„å­¦æ•™ç¨‹</title>
    <style>
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      div.columns{display: flex; gap: min(4vw, 1.5em);}
      div.column{flex: auto; overflow-x: auto;}
      div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
      ul.task-list{list-style: none;}
      ul.task-list li input[type="checkbox"] {
        width: 0.8em;
        margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
        vertical-align: middle;
      }
      /* CSS for syntax highlighting */
      html { -webkit-text-size-adjust: 100%; }
      pre > code.sourceCode { white-space: pre; position: relative; }
      pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
      pre > code.sourceCode > span:empty { height: 1.2em; }
      .sourceCode { overflow: visible; }
      code.sourceCode > span { color: inherit; text-decoration: inherit; }
      div.sourceCode { margin: 1em 0; }
      pre.sourceCode { margin: 0; }
      @media screen {
      div.sourceCode { overflow: auto; }
      }
      @media print {
      pre > code.sourceCode { white-space: pre-wrap; }
      pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
      }
      pre.numberSource code
        { counter-reset: source-line 0; }
      pre.numberSource code > span
        { position: relative; left: -4em; counter-increment: source-line; }
      pre.numberSource code > span > a:first-child::before
        { content: counter(source-line);
          position: relative; left: -1em; text-align: right; vertical-align: baseline;
          border: none; display: inline-block;
          -webkit-touch-callout: none; -webkit-user-select: none;
          -khtml-user-select: none; -moz-user-select: none;
          -ms-user-select: none; user-select: none;
          padding: 0 4px; width: 4em;
        }
      pre.numberSource { margin-left: 3em;  padding-left: 4px; }
      div.sourceCode
        {   }
      @media screen {
      pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
      }
    </style>

    <style>
      body.hypothesis-enabled #quarto-embed-header {
        padding-right: 36px;
      }

      #quarto-embed-header {
        height: 3em;
        width: 100%;
        display: flex;
        justify-content: space-between;
        align-items: center;
        border-bottom: solid 1px;
      }

      #quarto-embed-header h6 {
        font-size: 1.1em;
        padding-top: 0.6em;
        margin-left: 1em;
        margin-right: 1em;
        font-weight: 400;
      }

      #quarto-embed-header a.quarto-back-link,
      #quarto-embed-header a.quarto-download-embed {
        font-size: 0.8em;
        margin-top: 1em;
        margin-bottom: 1em;
        margin-left: 1em;
        margin-right: 1em;
      }

      .quarto-back-container {
        padding-left: 0.5em;
        display: flex;
      }

      .headroom {
          will-change: transform;
          transition: transform 200ms linear;
      }

      .headroom--pinned {
          transform: translateY(0%);
      }

      .headroom--unpinned {
          transform: translateY(-100%);
      }      
    </style>

    <script>
    window.document.addEventListener("DOMContentLoaded", function () {

      var header = window.document.querySelector("#quarto-embed-header");
      const titleBannerEl = window.document.querySelector("body > #title-block-header");
      if (titleBannerEl) {
        titleBannerEl.style.paddingTop = header.clientHeight + "px";
      }
      const contentEl = window.document.getElementById('quarto-content');
      for (const child of contentEl.children) {
        child.style.paddingTop = header.clientHeight + "px";
        child.style.marginTop = "1em";
      }

      // Use the article root if the `back` call doesn't work. This isn't perfect
      // but should typically work
      window.quartoBackToArticle = () => {
        var currentUrl = window.location.href;
        window.history.back();
        setTimeout(() => {
            // if location was not changed in 100 ms, then there is no history back
            if(currentUrl === window.location.href){              
                // redirect to site root
                window.location.href = "index.html";
            }
        }, 100);
      }

      const headroom = new window.Headroom(header, {
        tolerance: 5,
        onPin: function () {
        },
        onUnpin: function () {
        },
      });
      headroom.init();
    });
    </script>

    
<script src="site_libs/manuscript-notebook/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dc55a5b9e770e841cd82e46aadbfb9b0.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-4d7f0bce1131f3e5f9547cd857cfbfc8.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
     <script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>  
      </head>

  <body class="quarto-notebook quarto-light">
    <div id="quarto-embed-header" class="headroom fixed-top bg-primary">
      
      <a onclick="window.quartoBackToArticle(); return false;" class="btn btn-primary quarto-back-link" href=""><i class="bi bi-caret-left"></i> Back to Article</a>
      <h6><i class="bi bi-journal-code"></i> ä»£è°¢ç»„å­¦æ•™ç¨‹</h6>

            <a href="./metabolim.qmd" class="btn btn-primary quarto-download-embed" download="metabolim.qmd">Download Source</a>
          </div>

     <header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">ä»£è°¢ç»„å­¦æ•™ç¨‹</h1>
          </div>

    
    <div class="quarto-title-meta-container">
      <div class="quarto-title-meta-column-start">
            <div class="quarto-title-meta-author">
          <div class="quarto-title-meta-heading">Author</div>
          <div class="quarto-title-meta-heading">Affiliation</div>
          
                <div class="quarto-title-meta-contents">
            <p class="author">JAYZ </p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        The University OF Myself
                      </p>
                  </div>
                    </div>
        
        <div class="quarto-title-meta">

                      
          
                
              </div>
      </div>
      <div class="quarto-title-meta-column-end quarto-other-formats-target">
      </div>
    </div>



    <div class="quarto-other-links-text-target">
    </div>  </div>
</header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#metabolomicsproject-investigating-the-metabolic-impact-of-metforminäºŒç”²åŒå¼§-on-liver-cancer-cells" id="toc-metabolomicsproject-investigating-the-metabolic-impact-of-metforminäºŒç”²åŒå¼§-on-liver-cancer-cells" class="nav-link active" data-scroll-target="#metabolomicsproject-investigating-the-metabolic-impact-of-metforminäºŒç”²åŒå¼§-on-liver-cancer-cells">ğŸ˜‡Metabolomicsï¼šProject: Investigating the Metabolic Impact of Metformin(äºŒç”²åŒå¼§) on Liver Cancer CellsğŸ˜¶â€ğŸŒ«ï¸</a>
  <ul class="collapse">
  <li><a href="#project-setup-and-raw-data-processing" id="toc-project-setup-and-raw-data-processing" class="nav-link" data-scroll-target="#project-setup-and-raw-data-processing">ğŸ˜œProject setup and Raw Data Processing ğŸ¦„</a>
  <ul class="collapse">
  <li><a href="#lesson-1-project-setup-data-organization" id="toc-lesson-1-project-setup-data-organization" class="nav-link" data-scroll-target="#lesson-1-project-setup-data-organization"><strong>Lesson 1: Project Setup &amp; Data Organization</strong>ğŸ¦„</a></li>
  <li><a href="#practical-application-setting-up-our-project" id="toc-practical-application-setting-up-our-project" class="nav-link" data-scroll-target="#practical-application-setting-up-our-project"><strong>Practical Application: Setting up our Project</strong></a></li>
  <li><a href="#lesson-1-summary-status-check" id="toc-lesson-1-summary-status-check" class="nav-link" data-scroll-target="#lesson-1-summary-status-check"><strong>Lesson 1: Summary &amp; Status Check</strong></a></li>
  <li><a href="#lesson-2-the-core-challenge---peak-picking-feature-detection" id="toc-lesson-2-the-core-challenge---peak-picking-feature-detection" class="nav-link" data-scroll-target="#lesson-2-the-core-challenge---peak-picking-feature-detection"><strong>Lesson 2: The Core Challenge - Peak Picking &amp; Feature Detection</strong>ğŸ¤‘</a></li>
  <li><a href="#practical-application-finding-features-in-our-project" id="toc-practical-application-finding-features-in-our-project" class="nav-link" data-scroll-target="#practical-application-finding-features-in-our-project"><strong>Practical Application: Finding Features in our Project</strong></a></li>
  <li><a href="#lesson-2-summary-status-check" id="toc-lesson-2-summary-status-check" class="nav-link" data-scroll-target="#lesson-2-summary-status-check"><strong>Lesson 2: Summary &amp; Status Check</strong></a></li>
  <li><a href="#dont-forget-qc" id="toc-dont-forget-qc" class="nav-link" data-scroll-target="#dont-forget-qc">Dont forget QCğŸ˜‹</a></li>
  <li><a href="#qc-in-a-metabolomics-workflow" id="toc-qc-in-a-metabolomics-workflow" class="nav-link" data-scroll-target="#qc-in-a-metabolomics-workflow">QC in a Metabolomics Workflow</a></li>
  <li><a href="#lets-add-the-code" id="toc-lets-add-the-code" class="nav-link" data-scroll-target="#lets-add-the-code">Letâ€™s Add the Code!</a></li>
  <li><a href="#lesson-3-retention-time-correction" id="toc-lesson-3-retention-time-correction" class="nav-link" data-scroll-target="#lesson-3-retention-time-correction"><strong>Lesson 3: Retention Time Correction</strong>ğŸ¤ </a></li>
  <li><a href="#practical-application-aligning-our-project-data" id="toc-practical-application-aligning-our-project-data" class="nav-link" data-scroll-target="#practical-application-aligning-our-project-data"><strong>Practical Application: Aligning Our Project Data</strong></a></li>
  <li><a href="#lesson-3-summary-status-check" id="toc-lesson-3-summary-status-check" class="nav-link" data-scroll-target="#lesson-3-summary-status-check"><strong>Lesson 3: Summary &amp; Status Check</strong></a></li>
  <li><a href="#lesson-4-feature-grouping-or-correspondence" id="toc-lesson-4-feature-grouping-or-correspondence" class="nav-link" data-scroll-target="#lesson-4-feature-grouping-or-correspondence">Lesson 4: Feature Grouping (or â€œCorrespondenceâ€)ğŸ§</a></li>
  <li><a href="#practical-application-grouping-features-in-our-project" id="toc-practical-application-grouping-features-in-our-project" class="nav-link" data-scroll-target="#practical-application-grouping-features-in-our-project"><strong>Practical Application: Grouping Features in our Project</strong></a></li>
  <li><a href="#lesson-4-summary-status-check" id="toc-lesson-4-summary-status-check" class="nav-link" data-scroll-target="#lesson-4-summary-status-check"><strong>Lesson 4: Summary &amp; Status Check</strong></a></li>
  </ul></li>
  <li><a href="#part-2from-features-to-a-data-matrix" id="toc-part-2from-features-to-a-data-matrix" class="nav-link" data-scroll-target="#part-2from-features-to-a-data-matrix">ğŸŸPart 2ï¼šFrom Features to a Data MatrixğŸ¦‹</a>
  <ul class="collapse">
  <li><a href="#lesson-5-filling-missing-peaks" id="toc-lesson-5-filling-missing-peaks" class="nav-link" data-scroll-target="#lesson-5-filling-missing-peaks">Lesson 5: Filling Missing Peaks ğŸ¥©</a></li>
  <li><a href="#lesson-5-summary-status-check" id="toc-lesson-5-summary-status-check" class="nav-link" data-scroll-target="#lesson-5-summary-status-check"><strong>Lesson 5: Summary &amp; Status Check</strong></a></li>
  <li><a href="#lesson-6-annotation-with-camera" id="toc-lesson-6-annotation-with-camera" class="nav-link" data-scroll-target="#lesson-6-annotation-with-camera">Lesson 6: Annotation with <code>CAMERA</code> âš½</a></li>
  <li><a href="#lesson-6-summary-status-check" id="toc-lesson-6-summary-status-check" class="nav-link" data-scroll-target="#lesson-6-summary-status-check"><strong>Lesson 6: Summary &amp; Status Check</strong></a></li>
  <li><a href="#lesson-7-building-the-final-data-matrix-normalization" id="toc-lesson-7-building-the-final-data-matrix-normalization" class="nav-link" data-scroll-target="#lesson-7-building-the-final-data-matrix-normalization">Lesson 7: Building the Final Data Matrix &amp; NormalizationğŸ¦ª</a></li>
  <li><a href="#lesson-7-summary-status-check" id="toc-lesson-7-summary-status-check" class="nav-link" data-scroll-target="#lesson-7-summary-status-check"><strong>Lesson 7: Summary &amp; Status Check</strong></a></li>
  </ul></li>
  <li><a href="#part-3-the-payoff---statistical-analysis-and-biological-interpretation" id="toc-part-3-the-payoff---statistical-analysis-and-biological-interpretation" class="nav-link" data-scroll-target="#part-3-the-payoff---statistical-analysis-and-biological-interpretation">ğŸ•Šï¸Part 3: The Payoff - Statistical Analysis and Biological InterpretationğŸ§¶</a>
  <ul class="collapse">
  <li><a href="#lesson-8-univariateå•å˜é‡-and-multivariateå¤šå˜é‡-statistics" id="toc-lesson-8-univariateå•å˜é‡-and-multivariateå¤šå˜é‡-statistics" class="nav-link" data-scroll-target="#lesson-8-univariateå•å˜é‡-and-multivariateå¤šå˜é‡-statistics">Lesson 8: Univariate(å•å˜é‡) and Multivariate(å¤šå˜é‡) StatisticsğŸ¤—</a></li>
  <li><a href="#lesson-8-summary-status-check" id="toc-lesson-8-summary-status-check" class="nav-link" data-scroll-target="#lesson-8-summary-status-check"><strong>Lesson 8: Summary &amp; Status Check</strong></a></li>
  </ul></li>
  <li><a href="#lesson-9-metabolite-identification-and-annotation-the-deeper-dive" id="toc-lesson-9-metabolite-identification-and-annotation-the-deeper-dive" class="nav-link" data-scroll-target="#lesson-9-metabolite-identification-and-annotation-the-deeper-dive">Lesson 9: Metabolite Identification and Annotation (The Deeper Dive)ğŸ¤ </a>
  <ul class="collapse">
  <li><a href="#lesson-9-summary-status-check" id="toc-lesson-9-summary-status-check" class="nav-link" data-scroll-target="#lesson-9-summary-status-check"><strong>Lesson 9: Summary &amp; Status Check</strong></a></li>
  <li><a href="#lesson-10-pathway-and-enrichment-analysis" id="toc-lesson-10-pathway-and-enrichment-analysis" class="nav-link" data-scroll-target="#lesson-10-pathway-and-enrichment-analysis">Lesson 10: Pathway and Enrichment AnalysisğŸª‚</a></li>
  <li><a href="#practical-application-the-code-in-chunks" id="toc-practical-application-the-code-in-chunks" class="nav-link" data-scroll-target="#practical-application-the-code-in-chunks"><strong>Practical Application: The Code in Chunks</strong></a></li>
  <li><a href="#grand-conclusion-of-the-entire-metabolomics-project" id="toc-grand-conclusion-of-the-entire-metabolomics-project" class="nav-link" data-scroll-target="#grand-conclusion-of-the-entire-metabolomics-project"><strong>Grand Conclusion of the Entire Metabolomics Project</strong></a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">      

       <section id="metabolomicsproject-investigating-the-metabolic-impact-of-metforminäºŒç”²åŒå¼§-on-liver-cancer-cells" class="level1">
<h1>ğŸ˜‡Metabolomicsï¼šProject: Investigating the Metabolic Impact of Metformin(äºŒç”²åŒå¼§) on Liver Cancer CellsğŸ˜¶â€ğŸŒ«ï¸</h1>
<hr>
<section id="project-setup-and-raw-data-processing" class="level2">
<h2 class="anchored" data-anchor-id="project-setup-and-raw-data-processing">ğŸ˜œProject setup and Raw Data Processing ğŸ¦„</h2>
<hr>
<section id="lesson-1-project-setup-data-organization" class="level3">
<h3 class="anchored" data-anchor-id="lesson-1-project-setup-data-organization"><strong>Lesson 1: Project Setup &amp; Data Organization</strong>ğŸ¦„</h3>
<p><strong>Goal:</strong> To understand the basic requirements and set up a structured environment for a metabolomics project.</p>
<section id="concept-1-the-necessary-tools-and-data-format" class="level4">
<h4 class="anchored" data-anchor-id="concept-1-the-necessary-tools-and-data-format"><strong>Concept 1: The Necessary Tools and Data Format</strong></h4>
<p>In bioinformatics, especially when using open-source tools like R, we cannot work directly with the files that come off the mass spectrometer (e.g., .raw, .d). These are proprietary â€œclosedâ€ formats.</p>
<ul>
<li><p><strong>The Universal Language:</strong> The open-source community has created a universal format called <strong>mzML</strong>. Think of it as the PDF or JPG of mass spectrometry. Itâ€™s a standardized format that any tool can read.</p></li>
<li><p><strong>The Translator:</strong> A free, essential program called <strong>ProteoWizard</strong> (specifically <strong><em>its msConvert tool</em></strong>) is the standard for translating from proprietary formats to mzML.</p></li>
<li><p><strong>The â€œWorkbenchâ€:</strong> For metabolomics in R, the most important software is a package from Bioconductor called <strong><em><code>xcms</code></em></strong> . It is a complete ecosystem for processing metabolomics data, from the raw files to the final feature list. It is built on top of another package called <code>MSnbase</code>, which provides the fundamental tools for handling mass spec data.</p></li>
</ul>
</section>
<section id="concept-2-the-importance-of-project-structure" class="level4">
<h4 class="anchored" data-anchor-id="concept-2-the-importance-of-project-structure"><strong>Concept 2: The Importance of Project Structure</strong></h4>
<p>A bioinformatics project involves many files: raw data, processed data, scripts, figures, and reports. Without a logical folder structure from the very beginning, a project can quickly become chaotic and impossible to reproduce. A clean, organized project is the hallmark of a professional bioinformatician.</p>
</section>
</section>
<section id="practical-application-setting-up-our-project" class="level3">
<h3 class="anchored" data-anchor-id="practical-application-setting-up-our-project"><strong>Practical Application: Setting up our Project</strong></h3>
<p>Now, letâ€™s apply these concepts to our Metformin project.</p>
<p><strong>Action 1: Create the Project Folders</strong><br>
On your computer, create a main folder for the project. Inside it, create a set of sub-folders. This structure will keep everything tidy.</p>
<p><strong>codeCode</strong></p>
<pre><code>Project_HepG2_Metformin/
â”œâ”€â”€ data_mzML/         &lt;-- Our converted mzML files will go here
â”œâ”€â”€ data_processed/    &lt;-- Intermediate R objects we save will go here
â”œâ”€â”€ scripts/           &lt;-- Our R scripts will live here
â””â”€â”€ figures/           &lt;-- The plots we generate will be saved here</code></pre>
<p><strong>Action 2: Prepare the R Environment</strong><br>
We need to install the specialized packages. Think of this as stocking our workbench with the right tools before we start.</p>
<ul>
<li>Open RStudio. In the console, run these commands:</li>
</ul>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install the BiocManager, which is the installer for all bioinformatics packages in R</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">requireNamespace</span>(<span class="st">"BiocManager"</span>, <span class="at">quietly =</span> <span class="cn">TRUE</span>))</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">install.packages</span>(<span class="st">"BiocManager"</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Now use BiocManager to install the essential metabolomics packages</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>BiocManager<span class="sc">::</span><span class="fu">install</span>(<span class="fu">c</span>(<span class="st">"xcms"</span>, <span class="st">"MSnbase"</span>))</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Also install the tidyverse, a collection of packages for general data science</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">"tidyverse"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Action 3: Convert the Raw Data</strong><br>
Letâ€™s assume the lab has given us 10 <code>Thermo&nbsp;.raw</code>&nbsp;files. We must convert them to&nbsp;<code>mzML.</code></p>
<ol type="1">
<li><p>Open the msConvert program (from the ProteoWizard suite).</p></li>
<li><p>Add the 10 <code>.raw</code> files.</p></li>
<li><p>Set the output format to <strong>mzML</strong>.</p></li>
<li><p><strong>Crucially</strong>, for metabolomics, we do <strong>not</strong> apply a â€œPeak Pickingâ€ filter here. <code>xcms</code> is designed to work with the richer â€œprofileâ€ data to find the faint metabolic peaks.</p></li>
<li><p>Set the output directory to your new data_mzML folder.</p></li>
<li><p>Click â€œStartâ€.</p></li>
</ol>
<p><strong>Action 4: Set up the RStudio Project and Script</strong><br>
To make our lives easier, we will create an RStudio Project file. This automatically manages our working directory.</p>
<ol type="1">
<li><p>In RStudio, go to File &gt; New Projectâ€¦ &gt; Existing Directory.</p></li>
<li><p>Browse to and select your Project_HepG2_Metformin folder.</p></li>
<li><p>RStudio will restart and youâ€™ll see an .Rproj file in your project folder.</p></li>
<li><p>Now, create our first script: File &gt; New File &gt; R Script.</p></li>
<li><p>Save it inside the scripts folder as 01_xcms_processing.R.</p></li>
</ol>
</section>
<section id="lesson-1-summary-status-check" class="level3">
<h3 class="anchored" data-anchor-id="lesson-1-summary-status-check"><strong>Lesson 1: Summary &amp; Status Check</strong></h3>
<p>We have successfully completed the foundational setup.</p>
<ul>
<li><p><strong>Conceptually</strong>, we understand that we need to use an open data format (mzML) and that <code>xcms</code> is our primary tool in R for processing this data. We also understand the critical importance of an organized project folder.</p></li>
<li><p><strong>Practically</strong>, we have installed the necessary software, created a clean folder structure, converted our raw data, and set up our RStudio environment and our first script.</p></li>
</ul>
<p>We are now perfectly prepared to begin the actual data processing. Every step from here on will be code that we write in our <code>01_xcms_processing.R</code> script.</p>
<hr>
</section>
<section id="lesson-2-the-core-challenge---peak-picking-feature-detection" class="level3">
<h3 class="anchored" data-anchor-id="lesson-2-the-core-challenge---peak-picking-feature-detection"><strong>Lesson 2: The Core Challenge - Peak Picking &amp; Feature Detection</strong>ğŸ¤‘</h3>
<p><strong>Goal:</strong> To understand what a â€œfeatureâ€ is in metabolomics and to use the <code>xcms</code> package in R to <strong><em>automatically</em></strong> detect these features in each of our <em><code>LC-MS files</code></em> individually.</p>
<section id="concept-1-what-are-we-looking-for-the-feature" class="level4">
<h4 class="anchored" data-anchor-id="concept-1-what-are-we-looking-for-the-feature"><strong>Concept 1: What Are We Looking For? The â€œFeatureâ€</strong></h4>
<p>The raw LC-MS data is a three-dimensional landscape:</p>
<ol type="1">
<li><p><strong>Mass-to-Charge (m/z):</strong> Which ions are present.</p></li>
<li><p><strong>Retention Time (RT):</strong> When they come off the LC column.</p></li>
<li><p><strong>Intensity:</strong> How many of each ion there are.</p></li>
</ol>
<p><strong><em>A single metabolite doesnâ€™t just appear at one point.</em></strong> As the small sample plug of a metabolite travels off the column, it elutes over a short period of time, creating a peak shape. Therefore, a <strong>metabolic feature</strong> is a 2D mountain in the m/z vs.&nbsp;RT landscape. Our goal in this lesson is to find all of these â€œmountainsâ€ and characterize them.</p>
</section>
<section id="concept-2-the-extracted-ion-chromatogram-eicè‰²è°±å›¾" class="level4">
<h4 class="anchored" data-anchor-id="concept-2-the-extracted-ion-chromatogram-eicè‰²è°±å›¾"><strong>Concept 2: The Extracted Ion Chromatogram (EIC)(è‰²è°±å›¾)</strong></h4>
<p>How can we see these peaks? Imagine you take a very thin slice of the 3D data at a specific m/z value (e.g., all signals between m/z = 129.10 and 129.11). If you then plot the intensity of that slice over time, you get an <strong>Extracted Ion Chromatogram (EIC)</strong>. If a metabolite with that m/z exists, you will see a classic chromatographic peak (like a small bell curve) in the EIC.</p>
<p>The job of â€œpeak pickingâ€ algorithms is to automatically generate thousands of these EICs and find the bell-shaped peaks within them.</p>
</section>
<section id="concept-3-the-xcms-peak-picking-algorithm---centwave" class="level4">
<h4 class="anchored" data-anchor-id="concept-3-the-xcms-peak-picking-algorithm---centwave"><strong>Concept 3: The xcms Peak Picking Algorithm - centWave</strong></h4>
<p>xcms has several algorithms, but the most famous and widely used for high-resolution data (like ours) is called <strong><em>centWave</em></strong>. It works like this:</p>
<ol type="1">
<li><p>It divides the full m/z range <strong><em>into thousands of tiny, overlapping slices.</em></strong></p></li>
<li><p>For each slice, it creates an EIC.</p></li>
<li><p>It then applies advanced signal processing techniques (Continuous Wavelet Transform(è¿ç»­å°æ³¢å˜æ¢), which is where the â€œWaveâ€ in the name comes from) to the EIC to <strong><em>identify regions that look like real peaks and distinguish them from random noise.</em></strong></p></li>
<li><p>For each real peak it finds, it records key information: <strong><em>its exact m/z</em></strong>, <strong><em>the retention time</em></strong> at the apex of the peak, <strong><em>the peakâ€™s integrated area</em></strong> (the most important value for quantification), and other metrics.</p></li>
</ol>
<p>This process is performed <strong>independently on each of our 10 files.</strong> For now, the algorithm doesnâ€™t know or care that the files are related. Its only job is to generate a comprehensive list of all features found in each file, one by one.</p>
</section>
</section>
<section id="practical-application-finding-features-in-our-project" class="level3">
<h3 class="anchored" data-anchor-id="practical-application-finding-features-in-our-project"><strong>Practical Application: Finding Features in our Project</strong></h3>
<p>Now, letâ€™s write the R code in our <code>01_xcms_processing.R</code> script to apply these concepts.</p>
<p><strong>Action 1: Load Libraries and Define Files</strong><br>
The first step in our script is to load the necessary packages and tell R where to find our data files. We also need to create our â€œphenotypeâ€ data frame, which describes the experiment.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --------------------------------------------------------------------------</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Script: 01_xcms_processing.R</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Author: Your Name</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Date: 2025-09-03</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># --------------------------------------------------------------------------</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the essential libraries</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(xcms)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MSnbase)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 1. Load Data and Define Experimental Design ---</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the full paths to our converted mzML files</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>mzml_files <span class="ot">&lt;-</span> <span class="fu">list.files</span>(<span class="st">"./data_mzML"</span>, <span class="at">pattern =</span> <span class="st">".mzML"</span>, <span class="at">full.names =</span> <span class="cn">TRUE</span>, <span class="at">recursive =</span> <span class="cn">FALSE</span>)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Check that we found all 10 files</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(mzml_files)</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a 'phenotype' data frame (pData) describing the experiment.</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="co"># This is crucial for keeping track of our samples.</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>pdata <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>  <span class="at">sample_name =</span> <span class="fu">str_remove</span>(<span class="fu">basename</span>(mzml_files), <span class="st">".mzML"</span>),</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>  <span class="at">sample_group =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">"Control"</span>, <span class="dv">5</span>), <span class="fu">rep</span>(<span class="st">"Metformin"</span>, <span class="dv">5</span>)) <span class="co"># Assuming files are in order</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Look at our experimental design table</span></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(pdata)</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Read the raw data into a special on-disk MSnbase object.</span></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a><span class="co"># This is a memory-efficient way to handle large datasets.</span></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>raw_data <span class="ot">&lt;-</span> <span class="fu">readMSData</span>(<span class="at">files =</span> mzml_files, <span class="at">pData =</span> pdata, <span class="at">mode =</span> <span class="st">"onDisk"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li><strong>Run this code.</strong> You have now loaded all the file headers and your experimental design into the <code>raw_data</code> object without filling up your computerâ€™s memory.</li>
</ul>
<p><strong>Action 2: Define the Peak Picking Parameters</strong><br>
centWave is a powerful algorithm with many parameters. For now, we will start with a standard, robust set of parameters.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 2. Define Peak Picking Parameters ---</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co"># We create a parameter object. This is the modern way to work with xcms.</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># This makes our code clean and our analysis reproducible.</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>cwp <span class="ot">&lt;-</span> <span class="fu">CentWaveParam</span>(</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">ppm =</span> <span class="dv">5</span>,             <span class="co"># Mass accuracy in parts-per-million. A good value for modern instruments.</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">peakwidth =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">25</span>), <span class="co"># Expected range of peak widths in seconds.</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">snthresh =</span> <span class="dv">10</span>,         <span class="co"># Signal-to-noise ratio threshold.</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">prefilter =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">100</span>), <span class="co"># Prefilter for intensity. Peaks must have at least 3 points above 100 intensity.</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">mzdiff =</span> <span class="fl">0.01</span>          <span class="co"># Minimum difference in m/z for overlapping peaks.</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's look at our parameter object</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(cwp)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li><strong>Run this code.</strong> This creates an object cwp that holds all our instructions for the centWave algorithm. This is much better than typing all the numbers into one giant function call.</li>
</ul>
<p><strong>Action 3: Run the Peak Picking!</strong><br>
Now we apply our parameters to our raw data object. This is the first major computational step.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 3. Run Peak Picking ---</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># The 'findChromPeaks' function does the work.</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># It takes our raw data and our parameter object as input.</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># This will take some time to run as it processes each file individually.</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>xdata_peaks <span class="ot">&lt;-</span> <span class="fu">findChromPeaks</span>(raw_data, <span class="at">param =</span> cwp)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's inspect the results</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(xdata_peaks)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co"># We can also see how many peaks were found in each file</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="fu">chromPeakData</span>(xdata_peaks)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co"># And get a summary table</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>summary_peaks <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">table</span>(<span class="fu">chromPeakData</span>(xdata_peaks)<span class="sc">$</span>sample))</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(summary_peaks) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Sample_Index"</span>, <span class="st">"Num_Peaks"</span>)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>summary_peaks<span class="sc">$</span>Sample_Name <span class="ot">&lt;-</span> pdata<span class="sc">$</span>sample_name[summary_peaks<span class="sc">$</span>Sample_Index]</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(summary_peaks)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li><strong>Run this code.</strong> <code>xcms</code> is now processing your 10 files. When itâ€™s done, the <code>xdata_peaks</code> object will contain all the original raw data PLUS the results of the peak picking. The summary table will show you how many thousands of features were detected in each sample. You should see a relatively consistent number across all 10 files, which is a good first quality check.</li>
</ul>
</section>
<section id="lesson-2-summary-status-check" class="level3">
<h3 class="anchored" data-anchor-id="lesson-2-summary-status-check"><strong>Lesson 2: Summary &amp; Status Check</strong></h3>
<p>We have made a huge leap forward.</p>
<ul>
<li><p><strong>Conceptually</strong>, we understand that our goal is to find 2D peaks (features) in the m/z-RT data, and that algorithms like centWave do this by analyzing thousands of EICs. We also know that at this stage, each file is processed independently.</p></li>
<li><p><strong>Practically</strong>, we have loaded our data into a memory-efficient R object, defined a clear set of parameters for peak picking, and successfully executed the <code>findChromPeaks</code> function. We now have an object, xdata_peaks, that contains the locations and intensities of tens of thousands of features for each of our 10 samples.</p></li>
</ul>
<p>The problem now is that the feature list for â€œControl_1â€ is completely independent of the list for â€œControl_2â€. The next critical step is to correct for shifts in retention time so we can begin to match them up.</p>
<hr>
</section>
<section id="dont-forget-qc" class="level3">
<h3 class="anchored" data-anchor-id="dont-forget-qc">Dont forget QCğŸ˜‹</h3>
<p><strong>QC is not only needed, it is arguably even more critical in metabolomics than in proteomics.</strong></p>
<p>The reason is that metabolites are small, chemically diverse molecules that are much <strong><em>more sensitive</em></strong> to tiny variations in the experimental process (sample extraction, temperature, column pressure, etc.). Furthermore, the identification of metabolites is a much harder problem, so <strong><em>we rely heavily on the quality and consistency of our raw data</em></strong> (m/z and retention time) to have any confidence in our results.</p>
</section>
<section id="qc-in-a-metabolomics-workflow" class="level3">
<h3 class="anchored" data-anchor-id="qc-in-a-metabolomics-workflow">QC in a Metabolomics Workflow</h3>
<p>You donâ€™t just do QC once. Itâ€™s a continuous process that you perform at multiple stages.</p>
<section id="stage-1-before-you-even-start-xcms-initial-raw-data-qc" class="level4">
<h4 class="anchored" data-anchor-id="stage-1-before-you-even-start-xcms-initial-raw-data-qc"><strong>Stage 1: Before You Even Start xcms (Initial Raw Data QC)</strong></h4>
<p>This should be done right after loading the data in <strong>Lesson 2, Action 1</strong>.</p>
<p><strong>1. Total Ion Chromatogram (TIC) - The â€œHeartbeatâ€ of the Run:</strong></p>
<ul>
<li><p><strong>Concept:</strong> Exactly the same as in proteomics. We plot the sum of all ion intensities in every scan against the retention time.</p></li>
<li><p><strong>What it tells you:</strong> Itâ€™s your first and best look at the stability of the LC-MS system.</p>
<ul>
<li><p><strong>GOOD:</strong> TICs for all 10 replicates should have <strong><em>similar shapes, peak structures, and overall intensity ranges.</em></strong> This shows the chromatography and spray stability were consistent.</p></li>
<li><p><strong>BAD:</strong> One sample has a TIC that is 10x lower than the others. Or a TIC shows a sudden, sharp drop to zero. These are â€œoutlierâ€ runs that are technical failures. You should seriously consider <strong>removing them from the analysis</strong> before you even start peak picking.</p></li>
</ul></li>
<li><p><strong>How to do it in R:</strong> The chromatogram function in MSnbase does this perfectly, just as we did in the proteomics practical section.</p></li>
</ul>
<p><strong>2. Base Peak Chromatogram (BPC) - The â€œLoudest Signalâ€:</strong></p>
<ul>
<li><p><strong>Concept:</strong> Very similar to the TIC, but instead of summing all ions in a scan, it just plots the intensity of the single most intense ion.</p></li>
<li><p><strong>What it tells you:</strong> Itâ€™s less sensitive to background noise and can sometimes <strong><em>give a clearer picture of the major chromatographic peaks</em></strong>. Itâ€™s an excellent companion plot to the TIC. Consistent BPCs across replicates are a very good sign.</p></li>
<li><p><strong>How to do it in R:</strong> The same <code>chromatogram</code> function is used, but with <code>aggregationFun = "max".</code></p></li>
</ul>
</section>
<section id="stage-2-after-peak-picking-the-qc-we-are-about-to-do" class="level4">
<h4 class="anchored" data-anchor-id="stage-2-after-peak-picking-the-qc-we-are-about-to-do"><strong>Stage 2: After Peak Picking (The QC we are about to do)</strong></h4>
<p>Once <code>xcms</code> has found the features in each file, we can perform even more powerful QC.</p>
<p><strong>3. Total Number of Features:</strong></p>
<ul>
<li><p><strong>Concept:</strong> The summary_peaks table we just created in Lesson 2 is a QC step!</p></li>
<li><p><strong>What it tells you:</strong> While not expected to be identical, the total number of features found in each replicate should be in the same ballpark. If one sample suddenly has half (or double) the number of features, itâ€™s a major red flag that something went wrong with that specific sample.</p></li>
</ul>
<p><strong>4. Mass Accuracy - The â€œRulerâ€ of the Instrument:</strong></p>
<ul>
<li><p><strong>Concept:</strong> In metabolomics, we donâ€™t have a search engine to tell us the â€œtrueâ€ mass of a peptide like in proteomics. So, how do we check mass accuracy? We often rely on <strong>known contaminants or internal standards</strong>.</p></li>
<li><p><strong>What it tells you:</strong> If you know there is always a specific plasticizer(å¢å¡‘å‰‚) contaminant with a known mass of m/z 391.2842, you can plot the measured m/z of that peak in every sample. If itâ€™s consistently measured at 391.2840 +/- 0.0005, your mass accuracy is excellent (within a few ppm). If itâ€™s drifting all over the place, your instrument was not stable, and your confidence in identifying unknown metabolites will be very low.</p></li>
<li><p><strong>How to do it:</strong> This is a more manual process where you would plot the EIC of a known mass, find the peak, and check its measured m/z in each file.</p></li>
</ul>
<p><strong>5. Consistency of Retention Times for Key Metabolites (Before Correction):</strong></p>
<ul>
<li><p><strong>Concept:</strong> Pick a few well-known, abundant metabolites you expect to see (e.g., glutamine(è°·æ°¨é…°èƒº), leucine(äº®æ°¨é…¸)).</p></li>
<li><p><strong>What it tells you:</strong> Plot their EICs for all 10 samples on one graph. You will almost certainly see that their retention times are not perfectly aligned. They will drift from run to run. Seeing this drift <strong>is the entire motivation for our next lesson (Lesson 3: Retention Time Correction).</strong> This QC step proves why the next processing step is absolutely necessary.</p></li>
</ul>
</section>
</section>
<section id="lets-add-the-code" class="level3">
<h3 class="anchored" data-anchor-id="lets-add-the-code">Letâ€™s Add the Code!</h3>
<p>You are so right, we should have done this. Letâ€™s add the crucial TIC and BPC plotting code to our <code>01_xcms_processing.R</code> script. The perfect place is right after we create the raw_data object in <strong>Action 1 of Lesson 2</strong>.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- ADDENDUM: Initial Raw Data QC ---</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co"># This code should be run after creating the 'raw_data' object</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Plot the Total Ion Chromatogram (TIC)</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>tic_plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> <span class="fu">as.data.frame</span>(<span class="fu">chromatogram</span>(raw_data, <span class="at">aggregationFun =</span> <span class="st">"sum"</span>)),</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>            <span class="fu">aes</span>(<span class="at">x =</span> rtime <span class="sc">/</span> <span class="dv">60</span>, <span class="at">y =</span> intensity, <span class="at">group =</span> sample_name, <span class="at">color =</span> sample_group)) <span class="sc">+</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_viridis_d</span>() <span class="sc">+</span> <span class="co"># Use a nice color palette</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Total Ion Chromatogram (TIC)"</span>,</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Retention Time (minutes)"</span>,</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Total Intensity"</span>) <span class="sc">+</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(tic_plot)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="fu">ggsave</span>(<span class="st">"figures/01_raw_tic.png"</span>, tic_plot, <span class="at">width =</span> <span class="dv">10</span>, <span class="at">height =</span> <span class="dv">6</span>)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Plot the Base Peak Chromatogram (BPC)</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>bpc_plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> <span class="fu">as.data.frame</span>(<span class="fu">chromatogram</span>(raw_data, <span class="at">aggregationFun =</span> <span class="st">"max"</span>)),</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>            <span class="fu">aes</span>(<span class="at">x =</span> rtime <span class="sc">/</span> <span class="dv">60</span>, <span class="at">y =</span> intensity, <span class="at">group =</span> sample_name, <span class="at">color =</span> sample_group)) <span class="sc">+</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_viridis_d</span>() <span class="sc">+</span></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Base Peak Chromatogram (BPC)"</span>,</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Retention Time (minutes)"</span>,</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Max Intensity"</span>) <span class="sc">+</span></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(bpc_plot)</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a><span class="fu">ggsave</span>(<span class="st">"figures/01_raw_bpc.png"</span>, bpc_plot, <span class="at">width =</span> <span class="dv">10</span>, <span class="at">height =</span> <span class="dv">6</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<hr>
</section>
<section id="lesson-3-retention-time-correction" class="level3">
<h3 class="anchored" data-anchor-id="lesson-3-retention-time-correction"><strong>Lesson 3: Retention Time Correction</strong>ğŸ¤ </h3>
<p><strong>Goal:</strong> <strong><em>To understand why retention times vary between LC-MS runs and to use an xcms algorithm to computationally align the data, ensuring that the same metabolite appears at the same adjusted retention time in every sample.</em></strong></p>
<section id="concept-1-the-problem---inevitable-chromatographic-drift" class="level4">
<h4 class="anchored" data-anchor-id="concept-1-the-problem---inevitable-chromatographic-drift"><strong>Concept 1: The Problem - Inevitable Chromatographic Drift</strong></h4>
<p>Imagine you are running a marathon. Even under identical conditions, you wonâ€™t finish ten marathons in the exact same time down to the millisecond. The same is true for molecules in an LC column.</p>
<p>Over the course of an experiment (which can take hours or days), small, unavoidable changes occur:</p>
<ul>
<li><p>The temperature of the room can fluctuate slightly.</p></li>
<li><p>The pressure from the LC pumps can vary minutely.</p></li>
<li><p>The chromatography column itself can age and degrade.</p></li>
</ul>
<p>The result is <strong>retention time drift</strong>. A metabolite that appears at 5.21 minutes in the first run might appear at 5.18 minutes in the fifth run and 5.25 minutes in the tenth run.</p>
<p><strong>Why is this a catastrophe for our analysis?</strong><br>
Our next goal (in Lesson 4) is to group features from different samples and say, â€œThese are all the same metabolite.â€ We do this by looking for features with a very similar m/z and retention time. <strong><em>If the retention times are drifting randomly, we will fail to group correctly.</em></strong> We might incorrectly split one metabolite into two separate groups, or incorrectly merge two different metabolites into one.</p>
<p><strong>Therefore, retention time correction is not an optional â€œcleanupâ€ step. It is an absolutely essential prerequisite for correct feature grouping.</strong></p>
</section>
<section id="concept-2-the-solution---alignment-algorithms" class="level4">
<h4 class="anchored" data-anchor-id="concept-2-the-solution---alignment-algorithms"><strong>Concept 2: The Solution - Alignment Algorithms</strong></h4>
<p><code>xcms</code> uses powerful algorithms to fix this drift. The goal is to create a â€œwarpingâ€ function(æ‰­æ›²å‡½æ•°) for each sample that shifts its retention time axis to match a reference (often a â€œvirtualâ€ average of all samples).</p>
<p>A common and robust algorithm is <strong><code>obiwarp</code></strong> (Ordered Bijective Interpolated Warping). You donâ€™t need to know the deep mathematics, but conceptually, it works like this:</p>
<ol type="1">
<li><p>It creates a â€œconsensusâ€(å…±è¯†) signal by averaging all the TICs.</p></li>
<li><p>For each individual sampleâ€™s TIC, it finds the optimal way to stretch and squeeze its time axis to make it align perfectly with the consensus signal.</p></li>
<li><p>It saves this â€œwarpingâ€ function. Later, it will apply this exact same transformation to all the features that were detected in that sample.</p></li>
</ol>
</section>
<section id="concept-3-trust-but-verify---how-do-we-check-the-alignment" class="level4">
<h4 class="anchored" data-anchor-id="concept-3-trust-but-verify---how-do-we-check-the-alignment"><strong>Concept 3: â€œTrust, but Verifyâ€ - How Do We Check the Alignment?</strong></h4>
<p>How do we know if the correction actually worked? We visualize!</p>
<ul>
<li><p><strong>Before Correction:</strong> We can plot the TICs for all samples. We will see the major peaks are slightly misaligned.</p></li>
<li><p><strong>After Correction:</strong> We plot the TICs again, but this time using the adjusted retention times. The major peaks should now line up almost perfectly. This visual confirmation is our proof that the algorithm succeeded.</p></li>
</ul>
</section>
</section>
<section id="practical-application-aligning-our-project-data" class="level3">
<h3 class="anchored" data-anchor-id="practical-application-aligning-our-project-data"><strong>Practical Application: Aligning Our Project Data</strong></h3>
<p>Letâ€™s add the code to our <code>01_xcms_processing.R</code> script.</p>
<p><strong>Action 1: Define the Alignment Parameters</strong><br>
Just like with peak picking, we first create a parameter object. This keeps our code clean and documents our choices.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 4. Define Retention Time Correction Parameters ---</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co"># We will use the obiwarp method.</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 'binSize' controls the coarseness of the alignment. A good default is 1.</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="co"># We will let xcms pick the best reference sample automatically.</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>obiwarp_param <span class="ot">&lt;-</span> <span class="fu">ObiwarpParam</span>(<span class="at">binSize =</span> <span class="dv">1</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's inspect our parameter object</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(obiwarp_param)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li><strong>Run this code.</strong> You have now created the <code>obiwarp_param</code> object which contains the instructions for the alignment algorithm.</li>
</ul>
<p><strong>Action 2: Run the Alignment</strong><br>
We apply this parameter object to our <code>xdata_peaks</code> object.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 5. Run Retention Time Correction ---</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co"># The 'adjustRtime' function performs the alignment.</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># It takes our peak-picked data and the new parameter object.</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co"># This step is computationally intensive.</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>xdata_aligned <span class="ot">&lt;-</span> <span class="fu">adjustRtime</span>(xdata_peaks, <span class="at">param =</span> obiwarp_param)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's inspect the new object. It now contains the aligned data.</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(xdata_aligned)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li><strong>Run this code.</strong> This will take a few minutes. <code>xcms</code> is calculating the warping functions and creating a new object, <code>xdata_aligned,</code> which contains all the previous information plus the new, adjusted retention times for every single feature.</li>
</ul>
<p><strong>Action 3: Verify the Result!</strong><br>
Did it work? Letâ€™s plot the TICs before and after.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 6. Verify the Alignment ---</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co"># A) GET RAW TICs (BEFORE CORRECTION)</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>raw_tics <span class="ot">&lt;-</span> <span class="fu">chromatogram</span>(xdata_peaks, <span class="at">aggregationFun =</span> <span class="st">"sum"</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co"># B) GET ALIGNED TICs (AFTER CORRECTION)</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># We can get these directly from our new object. It uses the adjusted times by default.</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>aligned_tics <span class="ot">&lt;-</span> <span class="fu">chromatogram</span>(xdata_aligned, <span class="at">aggregationFun =</span> <span class="st">"sum"</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="co"># C) PLOT THEM SIDE-BY-SIDE</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="co"># We'll use a little data wrangling to make a combined plot</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to data frames and add a label for the plot facet</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>raw_tics_df <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(raw_tics)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>raw_tics_df<span class="sc">$</span>type <span class="ot">&lt;-</span> <span class="st">"Before Correction"</span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>aligned_tics_df <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(aligned_tics)</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>aligned_tics_df<span class="sc">$</span>type <span class="ot">&lt;-</span> <span class="st">"After Correction"</span></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine the two data frames</span></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>combined_tics_df <span class="ot">&lt;-</span> <span class="fu">rbind</span>(raw_tics_df, aligned_tics_df)</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the plot</span></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>alignment_plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(combined_tics_df, <span class="fu">aes</span>(<span class="at">x =</span> rtime <span class="sc">/</span> <span class="dv">60</span>, <span class="at">y =</span> intensity, <span class="at">group =</span> sample_name, <span class="at">color =</span> sample_group)) <span class="sc">+</span></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> type, <span class="at">ncol =</span> <span class="dv">1</span>) <span class="sc">+</span> <span class="co"># This creates the two panels</span></span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_viridis_d</span>() <span class="sc">+</span></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Verification of Retention Time Alignment"</span>,</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Retention Time (minutes)"</span>,</span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Total Intensity"</span></span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the plot</span></span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(alignment_plot)</span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the plot</span></span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a><span class="fu">ggsave</span>(<span class="st">"figures/02_alignment_verification.png"</span>, alignment_plot, <span class="at">width =</span> <span class="dv">10</span>, <span class="at">height =</span> <span class="dv">8</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li><p><strong>Run this code.</strong> This will generate a two-panel plot.</p>
<ul>
<li><p><strong>The top panel (â€œBefore Correctionâ€):</strong> You will see the main peaks are clearly staggered and misaligned between the different colored lines (samples).</p></li>
<li><p><strong>The bottom panel (â€œAfter Correctionâ€):</strong> You should see a dramatic improvement. The main peaks should now be sitting almost perfectly on top of each other. This is our visual proof. We have successfully and verifiably aligned our data.</p></li>
</ul></li>
</ul>
</section>
<section id="lesson-3-summary-status-check" class="level3">
<h3 class="anchored" data-anchor-id="lesson-3-summary-status-check"><strong>Lesson 3: Summary &amp; Status Check</strong></h3>
<ul>
<li><p><strong>Conceptually</strong>, we understand that LC-MS runs are not perfectly stable and that this causes retention time drift, which is a critical problem we must solve before we can group features. We know that algorithms like obiwarp can correct this drift.</p></li>
<li><p><strong>Practically</strong>, we have defined parameters for, and successfully run, the adjustRtime function.</p></li>
<li><p><strong>Crucially</strong>, we have followed the â€œTrust, but Verifyâ€ principle by creating a before-and-after plot that visually confirms the success of our alignment step.</p></li>
</ul>
<p>Our data is now primed for the next major step. With the m/z values being accurate and the retention times now aligned, we are finally ready to ask the main question: â€œWhich of these tens of thousands of features from 10 different files actually represent the same metabolite?â€ This is the task of feature grouping.</p>
<hr>
</section>
<section id="lesson-4-feature-grouping-or-correspondence" class="level3">
<h3 class="anchored" data-anchor-id="lesson-4-feature-grouping-or-correspondence">Lesson 4: Feature Grouping (or â€œCorrespondenceâ€)ğŸ§</h3>
<p><strong>Goal:</strong> <strong><em>To understand how xcms groups individual features from all 10 samples into â€œfeature groups,â€ where each group represents a single, unique metabolic compound measured across the experiment.</em></strong></p>
<section id="concept-1-the-problem---from-many-lists-to-one-matrix" class="level4">
<h4 class="anchored" data-anchor-id="concept-1-the-problem---from-many-lists-to-one-matrix"><strong>Concept 1: The Problem - From Many Lists to One Matrix</strong></h4>
<p>Right now, our xdata_aligned object contains 10 separate lists of features.</p>
<ul>
<li><p>File 1 has a feature at (m/z=130.06, RT=2.51 min)</p></li>
<li><p>File 2 has a feature at (m/z=130.07, RT=2.52 min)</p></li>
<li><p>File 3 has a feature at (m/z=130.06, RT=2.50 min)</p></li>
<li><p>â€¦and so on.</p></li>
</ul>
<p>Our goal is to create a final data matrix where the <strong>rows are unique compounds</strong> and the <strong>columns are our samples</strong>. To do this, we need to figure out that the three features listed above are very likely measurements of the same compound.</p>
<p>The process of finding and linking these corresponding features is called <strong>grouping</strong> or <strong>correspondence</strong>.</p>
</section>
<section id="concept-2-the-solution---grouping-by-proximity" class="level4">
<h4 class="anchored" data-anchor-id="concept-2-the-solution---grouping-by-proximity"><strong>Concept 2: The Solution - Grouping by Proximity</strong></h4>
<p>How do we decide which features belong together? We look for features that are â€œcloseâ€ to each other in the chemical space we have just worked so hard to clean up:</p>
<ol type="1">
<li><p><strong>Mass-to-Charge (m/z):</strong> The m/z values must be very similar, within the known mass accuracy of our instrument (e.g., within 5 ppm).</p></li>
<li><p><strong>Retention Time (RT):</strong> The aligned retention times must also be very close, within a small window.</p></li>
</ol>
<p>The grouping algorithm in <code>xcms</code> essentially creates a â€œsearch windowâ€ around each feature and looks for other features from different samples that fall within that m/z and RT window.</p>
<p>The most common algorithm for this uses a <strong>density-based approach</strong>. Imagine plotting all the features from all 10 samples as points on a 2D graph of m/z vs.&nbsp;RT<strong><em>. The features that belong to the same compound will form a tight, dense cluster of points</em></strong>. The algorithmâ€™s job is to find these dense regions.</p>
</section>
<section id="concept-3-trust-but-verify---how-do-we-check-the-grouping" class="level4">
<h4 class="anchored" data-anchor-id="concept-3-trust-but-verify---how-do-we-check-the-grouping"><strong>Concept 3: â€œTrust, but Verifyâ€ - How Do We Check the Grouping?</strong></h4>
<p>This step is harder to verify with a single plot, but there are key metrics and visualizations we can use:</p>
<ol type="1">
<li><p><strong>Feature Group Summaries:</strong> We can check how many of our final feature groups contain a peak from only 1 sample, 2 samples, â€¦ up to all 10 samples. A good grouping should result in a large number of feature groups that contain peaks from most, if not all, of the samples within at least one condition (e.g., all 5 Control samples). A very high number of â€œsingletonâ€ groups (found in only one sample) might indicate the parameters were too strict.</p></li>
<li><p><strong>Extracted Ion Chromatogram (EIC) of a Feature Group:</strong> This is the most powerful verification. We can pick a single, final feature group from our results and ask xcms to plot the raw chromatograms for that specific m/z and RT range for all 10 samples. A well-grouped feature should show a clean, aligned peak in most, if not all, of the samples. This confirms that the algorithm correctly grouped the signals.</p></li>
</ol>
</section>
</section>
<section id="practical-application-grouping-features-in-our-project" class="level3">
<h3 class="anchored" data-anchor-id="practical-application-grouping-features-in-our-project"><strong>Practical Application: Grouping Features in our Project</strong></h3>
<p>Letâ€™s add the code to our <code>01_xcms_processing.R</code> script.</p>
<p><strong>Action 1: Define the Grouping Parameters</strong><br>
We need to tell the density-based algorithm how close is â€œclose enoughâ€ for m/z and RT.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 7. Define Feature Grouping Parameters ---</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co"># We will use the 'PeakDensity' method.</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>pdp <span class="ot">&lt;-</span> <span class="fu">PeakDensityParam</span>(</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">sampleGroups =</span> pdata<span class="sc">$</span>sample_group, <span class="co"># We provide our sample groups (Control, Metformin)</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">minFraction =</span> <span class="fl">0.5</span>,                 <span class="co"># A feature must be present in at least 50% of samples in at least ONE group to form a group. This is a key parameter to avoid noise.</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">bw =</span> <span class="dv">5</span>,                            <span class="co"># The bandwidth (standard deviation) of the RT grouping window in seconds.</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">ppm =</span> <span class="dv">5</span>                            <span class="co"># The ppm tolerance for grouping features in the m/z dimension.</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's inspect our parameter object</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(pdp)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li><strong>Run this code.</strong> You have now created the <code>pdp</code> object. The minFraction parameter is particularly important. Setting it to 0.5 means that to be considered a â€œrealâ€ feature group, a feature must be detected in at least 3 of the 5 replicates in either the Control group OR the Metformin group. This is a powerful way to filter out random, sporadic noise peaks.</li>
</ul>
<p><strong>Action 2: Run the Grouping</strong><br>
We apply this parameter object to our <code>xdata_aligned</code> object.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 8. Run Feature Grouping ---</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co"># The 'groupChromPeaks' function performs the correspondence.</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># This can also be a computationally intensive step.</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>xdata_grouped <span class="ot">&lt;-</span> <span class="fu">groupChromPeaks</span>(xdata_aligned, <span class="at">param =</span> pdp)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's inspect the new object.</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(xdata_grouped)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li><strong>Run this code.</strong> <code>xcms</code> is now searching through all the aligned features and clustering them into groups. The new <code>xdata_grouped</code> object now contains the final, linked feature groups.</li>
</ul>
<p><strong>Action 3: Verify the Result!</strong><br>
Letâ€™s look at the summary and then visualize a specific EIC.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 9. Verify the Grouping ---</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co"># A) FEATURE GROUP SUMMARY</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co"># The 'featureDefinitions' function gives us the final table of feature groups</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>feature_defs <span class="ot">&lt;-</span> <span class="fu">featureDefinitions</span>(xdata_grouped)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(feature_defs)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's check the size of the groups</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>summary_groups <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">table</span>(feature_defs<span class="sc">$</span>npeaks))</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(summary_groups) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Num_Samples"</span>, <span class="st">"Num_Feature_Groups"</span>)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(summary_groups)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="co"># B) VISUALIZE AN EIC FOR A SPECIFIC FEATURE GROUP</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's pick a feature that is present in all 10 samples (a high-quality one)</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a><span class="co"># We can find its index from the feature_defs table</span></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>feature_of_interest <span class="ot">&lt;-</span> <span class="st">"FT050"</span> <span class="co"># Let's assume this is an interesting one</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the chromatogram for this feature group</span></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>eic_plot <span class="ot">&lt;-</span> <span class="fu">plotChromPeaks</span>(xdata_grouped, <span class="at">feature =</span> feature_of_interest)</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the plot</span></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(eic_plot)</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the plot</span></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a><span class="fu">ggsave</span>(<span class="st">"figures/03_eic_verification.png"</span>, eic_plot, <span class="at">width =</span> <span class="dv">8</span>, <span class="at">height =</span> <span class="dv">6</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li><p><strong>Run this code.</strong></p>
<ul>
<li><p>The <code>summary_groups</code> table gives you an overview of the grouping quality. You want to see high numbers for 5 samples and 10 samples.</p></li>
<li><p>The <code>eic_plot</code> is your direct visual proof. It will show the raw data for a single feature group. You should see a nice, Gaussian-shaped peak present in most or all of the 10 chromatograms, and crucially, they should all be <strong>perfectly aligned</strong> at the same retention time. This proves that both the alignment (Lesson 3) and the grouping (Lesson 4) worked correctly.</p></li>
</ul></li>
</ul>
</section>
<section id="lesson-4-summary-status-check" class="level3">
<h3 class="anchored" data-anchor-id="lesson-4-summary-status-check"><strong>Lesson 4: Summary &amp; Status Check</strong></h3>
<p>This lesson marks the end of the core xcms pre-processing workflow.</p>
<ul>
<li><p><strong>Conceptually</strong>, we understand that the goal of grouping is to create a unified feature list by clustering individual peaks based on their proximity in the aligned RT vs.&nbsp;m/z space.</p></li>
<li><p><strong>Practically</strong>, we have defined parameters for, and successfully run, the groupChromPeaks function.</p></li>
<li><p><strong>Crucially</strong>, we have followed the â€œTrust, but Verifyâ€ principle by inspecting the feature group statistics and, most importantly, by plotting an EIC to visually confirm that the algorithm correctly grouped the signals from the raw data.</p></li>
</ul>
<p>We have successfully transformed 10 complex raw files into a single, coherent, and organized list of metabolic features. The hard part of the signal processing is now complete. Our next step will be to handle any missing values in this feature list and then format it into the final data matrix that we will use for our statistical analysis.</p>
<hr>
</section>
</section>
<section id="part-2from-features-to-a-data-matrix" class="level2">
<h2 class="anchored" data-anchor-id="part-2from-features-to-a-data-matrix">ğŸŸPart 2ï¼šFrom Features to a Data MatrixğŸ¦‹</h2>
<hr>
<section id="lesson-5-filling-missing-peaks" class="level3">
<h3 class="anchored" data-anchor-id="lesson-5-filling-missing-peaks">Lesson 5: Filling Missing Peaks ğŸ¥©</h3>
<section id="goal-our-goal-is-to-address-the-issue-of-missing-values-in-our-feature-table.-the-groupchrompeaks-function-linked-features-across-samples-but-some-samples-within-a-group-may-not-have-had-a-peak-detected-by-the-findchrompeaks-algorithm.-we-want-to-go-back-to-the-raw-data-for-those-specific-samples-and-integrate-the-signal-in-the-exact-location-where-the-peak-should-be-giving-us-a-more-complete-data-matrix-for-statistical-analysis." class="level4">
<h4 class="anchored" data-anchor-id="goal-our-goal-is-to-address-the-issue-of-missing-values-in-our-feature-table.-the-groupchrompeaks-function-linked-features-across-samples-but-some-samples-within-a-group-may-not-have-had-a-peak-detected-by-the-findchrompeaks-algorithm.-we-want-to-go-back-to-the-raw-data-for-those-specific-samples-and-integrate-the-signal-in-the-exact-location-where-the-peak-should-be-giving-us-a-more-complete-data-matrix-for-statistical-analysis."><strong>1. Goal :</strong> <em>Our goal is to address the issue of missing values in our feature table. The <code>groupChromPeaks</code> function linked features across samples, but some samples within a group may not have had a peak detected by the <code>findChromPeaks</code> algorithm. We want to go back to the raw data for those specific samples and integrate the signal in the exact location where the peak should be, giving us a more complete data matrix for statistical analysis.</em></h4>
</section>
<section id="underlying-logic" class="level4">
<h4 class="anchored" data-anchor-id="underlying-logic"><strong>2. Underlying Logic</strong></h4>
<ul>
<li><p><strong>Why are peaks â€œmissingâ€?</strong> A peak might be â€œmissingâ€ for two main reasons:</p>
<ol type="1">
<li><p><strong>True Absence:</strong> The metabolite is simply not present or is below the instrumentâ€™s detection limit in that sample. This is a biologically meaningful result.</p></li>
<li><p><strong>Technical Absence:</strong> The metabolite was present, but its <strong><em>signal was too low,</em></strong> too noisy, or too poorly shaped to be picked by the <code>findChromPeaks</code> algorithm, which had a strict signal-to-noise threshold.</p></li>
</ol></li>
<li><p><strong>The Problem:</strong> Standard statistical tests (like t-tests) cannot handle missing values (NA). Simply ignoring them or replacing them with zero is statistically invalid and throws away valuable information. A zero is a measured value; an NA means we donâ€™t know.</p></li>
<li><p><strong>The Solution (fillChromPeaks):</strong> The grouping step (Lesson 4) has given us a very precise map. For a given feature group, we know the exact m/z and the aligned retention time range where that metabolite appears in the samples where it was detected. The <code>fillChromPeaks</code> function uses this map. For every sample where a peak is missing within that group, it <strong><em>goes back to the original raw data file</em></strong> for that sample, extracts the chromatogram for that precise m/z and RT window, and integrates the signal there.</p>
<ul>
<li><p><strong><em>If there was a small, real peak that was missed, it will be integrated and we get a good quantitative value</em></strong>.</p></li>
<li><p>If there was only noise, it will <strong><em>integrate the noise,</em></strong> resulting in a very small, near-zero value, which is a much more accurate representation than a complete NA.</p></li>
</ul></li>
</ul>
</section>
<section id="practical-application-the-code" class="level4">
<h4 class="anchored" data-anchor-id="practical-application-the-code"><strong>3. Practical Application: The Code</strong></h4>
<p>Letâ€™s add the code to our <code>01_xcms_processing.R</code> script.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 10. Define Parameters for Peak Filling ---</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># We create a parameter object to be explicit about our method.</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># The 'expand' and 'fixed' parameters control the size of the integration window.</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co"># A small fixed value is often robust.</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>fcp <span class="ot">&lt;-</span> <span class="fu">FillChromPeaksParam</span>(<span class="at">expand =</span> <span class="dv">2</span>, <span class="at">fixed =</span> <span class="dv">1</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's inspect our parameter object</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(fcp)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li><strong>Action:</strong> Add this code to your script and run it. We have now defined the instructions for the peak filling algorithm.</li>
</ul>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 11. Run Peak Filling ---</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co"># The 'fillChromPeaks' function does the work.</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># It takes our grouped data object as input.</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co"># This step can be very fast as it's not searching, just integrating known locations.</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>xdata_filled <span class="ot">&lt;-</span> <span class="fu">fillChromPeaks</span>(xdata_grouped, <span class="at">param =</span> fcp)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's inspect the final object</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(xdata_filled)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li><strong>Action:</strong> Run this code. <code>xcms</code> is now iterating through your feature groups, finding the NAs, and integrating the signal from the raw data. The new <code>xdata_filled</code> object is our final, processed <code>xcms</code> object.</li>
</ul>
</section>
<section id="expected-outcome" class="level4">
<h4 class="anchored" data-anchor-id="expected-outcome"><strong>4. Expected Outcome</strong></h4>
<p>The <code>xdata_filled</code> object now contains the same feature groups as before, but the underlying data table has far fewer missing NA values. The intensities for previously missing peaks have been replaced with new, integrated quantitative values.</p>
</section>
<section id="verifiable-proof" class="level4">
<h4 class="anchored" data-anchor-id="verifiable-proof"><strong>5. Verifiable â€œProofâ€</strong></h4>
<p>How can we prove that this worked? We can directly compare the number of missing values for a specific feature before and after the filling step.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 12. Verify the Peak Filling ---</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co"># The 'featureValues' function extracts the final data matrix.</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 'value = "into"' gives the integrated peak area (intensity).</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co"># A) GET THE MATRIX BEFORE FILLING</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>matrix_before_filling <span class="ot">&lt;-</span> <span class="fu">featureValues</span>(xdata_grouped, <span class="at">value =</span> <span class="st">"into"</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="co"># B) GET THE MATRIX AFTER FILLING</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>matrix_after_filling <span class="ot">&lt;-</span> <span class="fu">featureValues</span>(xdata_filled, <span class="at">value =</span> <span class="st">"into"</span>)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="co"># C) COMPARE THE NUMBER OF NAs</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>na_counts_before <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">is.na</span>(matrix_before_filling))</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>na_counts_after <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">is.na</span>(matrix_after_filling))</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the proof</span></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Number of missing values BEFORE peak filling:"</span>, na_counts_before, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Number of missing values AFTER peak filling:"</span>, na_counts_after, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a><span class="co"># We can also look at a specific feature that had missing values.</span></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's find a feature group that was missing in some samples.</span></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a><span class="co"># (This requires a bit of code to find an example)</span></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>feature_info <span class="ot">&lt;-</span> <span class="fu">featureSummary</span>(xdata_grouped)</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>example_feature_row <span class="ot">&lt;-</span> <span class="fu">which</span>(feature_info<span class="sc">$</span>Metformin <span class="sc">&lt;</span> <span class="dv">5</span> <span class="sc">&amp;</span> feature_info<span class="sc">$</span>Metformin <span class="sc">&gt;</span> <span class="dv">0</span> <span class="sc">&amp;</span> feature_info<span class="sc">$</span>Control <span class="sc">==</span> <span class="dv">5</span>)[<span class="dv">1</span>]</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>example_feature_id <span class="ot">&lt;-</span> <span class="fu">rownames</span>(feature_info)[example_feature_row]</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">--- Verifying a single feature:"</span>, example_feature_id, <span class="st">"---</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="st">"Intensities BEFORE filling:"</span>)</span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(matrix_before_filling[example_feature_id, ])</span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">Intensities AFTER filling:"</span>)</span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(matrix_after_filling[example_feature_id, ])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li><p><strong>Action:</strong> Run this final block.</p></li>
<li><p><strong>Verification:</strong> The console output is our proof.</p>
<ol type="1">
<li><p>You will see a dramatic reduction in the total number of missing values. The â€œafterâ€ count will be much lower than the â€œbeforeâ€ count.</p></li>
<li><p>For the specific example feature, you will see a row of numbers printed for the â€œbeforeâ€ matrix that contains one or more NAs.</p></li>
<li><p>The row of numbers for the â€œafterâ€ matrix will now have those NAs replaced with small, positive numerical values. This is direct, verifiable evidence that the <code>fillChromPeaks</code> function did exactly what we intended.</p></li>
</ol></li>
</ul>
</section>
</section>
<section id="lesson-5-summary-status-check" class="level3">
<h3 class="anchored" data-anchor-id="lesson-5-summary-status-check"><strong>Lesson 5: Summary &amp; Status Check</strong></h3>
<ul>
<li><p><strong>Conceptually</strong>, we understand that missing peaks are a problem for statistics and that <code>xcms</code> provides a robust solution by re-integrating the raw signal in the expected location, based on the alignment data from samples where the peak was found.</p></li>
<li><p><strong>Practically</strong>, we have defined parameters for and run the <code>fillChromPeaks</code> function.</p></li>
<li><p><strong>Crucially</strong>, we have followed the â€œTrust, but Verifyâ€ principle by writing code that directly compares the data matrix before and after the step, proving that the number of missing values has been significantly reduced.</p></li>
</ul>
<hr>
</section>
<section id="lesson-6-annotation-with-camera" class="level3">
<h3 class="anchored" data-anchor-id="lesson-6-annotation-with-camera">Lesson 6: Annotation with <code>CAMERA</code> âš½</h3>
<section id="goal" class="level4">
<h4 class="anchored" data-anchor-id="goal"><strong>1. Goal</strong></h4>
<p><strong><em>Our goal is to â€œannotateâ€ the feature list from <code>xcms</code>. This means finding features that are related because they originate(èµ·æº) from the same parent metabolite(æ¯ä½“ä»£è°¢ç‰©). Specifically, we want to identify:</em></strong></p>
<ol type="1">
<li><p><strong>Isotopes:</strong> Peaks that have the same retention time but are ~1.00335 Da heavier (the mass difference of a Â¹Â³C isotope).</p></li>
<li><p><strong>Adducts(åŠ åˆç‰©):</strong> Peaks that have the <strong><em>same retention time but different m/z values</em></strong> corresponding to the s<strong><em>ame molecule binding with different ions</em></strong> (e.g., [M+H]âº, [M+Na]âº, [M+K]âº).</p></li>
</ol>
<p>By grouping these related features into â€œpseudospectra,(ä¼ªå…‰è°±)â€ we get a much <strong><em>cleaner list where each entry is a closer approximation of a single, unique compound.</em></strong> This is a critical step before database searching and statistical analysis.</p>
</section>
<section id="underlying-logic-1" class="level4">
<h4 class="anchored" data-anchor-id="underlying-logic-1"><strong>2. Underlying Logic</strong></h4>
<ul>
<li><p><strong>The Problem:</strong> A single metabolite, â€œM,â€ does not produce a single peak in the mass spectrometer. Due to natural isotope abundance and the chemistry of electrospray(ç”µå–·é›¾) ionization(ç”µç¦»), <strong><em>it will generate a whole family of related peaks.</em></strong></p>
<ul>
<li><p><strong>Isotopes:</strong> Youâ€™ll see the <strong><em>main peak</em></strong> (M), the M+1 peak (with one Â¹Â³C atom), the M+2 peak (with two Â¹Â³C atoms), etc. <code>xcms</code> will likely have <strong><em>picked all of these as separate features.</em></strong></p></li>
<li><p><strong>Adducts:</strong> In positive ion mode, the same molecule M can be detected as the protonated(è´¨å­åŒ–) form [M+H]âº, the sodium(é’ ) adduct [M+Na]âº, and the potassium(é’¾) adduct [M+K]âº. <code>xcms</code> will <strong><em>have picked these three as separate features, even though they all come from the same original compound.</em></strong></p></li>
</ul></li>
<li><p><strong>The Consequence:</strong> If we donâ€™t fix this, we will perform statistical tests on all these redundant features. We might find that [M+H]âº, [M+Na]âº, and the M+1 isotope are all â€œsignificantly changed.â€ <strong><em>This is not three independent discoveries;</em></strong> itâ€™s <strong>one discovery</strong> reported three times, <strong><em>which inflates our statistics and makes interpretation a mess.</em></strong></p></li>
<li><p><strong>The Solution (CAMERA):</strong> The <strong><code>CAMERA</code></strong> (Comprehensive Annotation of Mass Spectrometry data) package is designed specifically for this. It takes the feature list from <code>xcms</code> and uses a clever set of rules to find these relationships.</p>
<ol type="1">
<li><p>First, <strong><em>it groups features with very highly correlated intensities across all samples</em></strong> (features that go up and down together are likely related).</p></li>
<li><p>Then, within these correlated groups, <strong><em>it looks for specific, known mass differences</em></strong> that correspond to isotope patterns and common adducts ([Na-H] â‰ˆ 21.98 Da, [K-H] â‰ˆ 37.95 Da).(å¯»æ‰¾ä¸åŒä½ç´ æ¨¡å¼å’Œå¸¸è§åŠ åˆç‰©ç›¸å¯¹åº”çš„ç‰¹å®šå·²ç»çŸ¥é“çš„è´¨é‡å·®å¼‚)</p></li>
<li><p>it bundles(æ†ç»‘) all the features it identifies as belonging to one compound into a â€œpseudospectrumâ€ and assigns them the same group ID.</p></li>
</ol></li>
</ul>
</section>
<section id="practical-application-the-code-1" class="level4">
<h4 class="anchored" data-anchor-id="practical-application-the-code-1"><strong>3. Practical Application: The Code</strong></h4>
<p>This process is a bit different as <code>CAMERA</code> is a <strong><em>separate packag</em></strong>e that operates on the <code>xcms</code> object.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 13. Annotate Features with CAMERA ---</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="co"># This code continues in our '01_xcms_processing.R' script.</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the CAMERA library</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(CAMERA)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co"># CAMERA works on a special object type. We first need to convert our</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="co"># xcms object into an 'xsAnnotate' object.</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="co"># This step can take a moment and might print some status messages.</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>xa <span class="ot">&lt;-</span> <span class="fu">xsAnnotate</span>(xdata_filled)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Group features based on retention time. Features from the same</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a><span class="co"># compound should have the same RT.</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>xa_grouped <span class="ot">&lt;-</span> <span class="fu">groupFWHM</span>(xa)</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Annotate isotopes. This looks for peaks with the expected</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a><span class="co"># mass difference for C13 isotopes.</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>xa_isotopes <span class="ot">&lt;-</span> <span class="fu">findIsotopes</span>(xa_grouped)</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Annotate adducts and group them into pseudospectra.</span></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a><span class="co"># This is the key step where it looks for [M+H], [M+Na], etc.</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>xa_annotated <span class="ot">&lt;-</span> <span class="fu">findAdducts</span>(xa_isotopes)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li><strong>Action:</strong> Add this code block to your script and run it. You are performing the three main steps of CAMERAâ€™s workflow. The final object, <code>xa_annotated</code>, contains all the previous <code>xcms</code> data <strong><em>plus a wealth of new annotation information.</em></strong></li>
</ul>
</section>
<section id="expected-outcome-1" class="level4">
<h4 class="anchored" data-anchor-id="expected-outcome-1"><strong>4. Expected Outcome</strong></h4>
<p>The primary output is a table of results that links features together. We expect to see a <strong><em>new column, <code>pcgroup</code></em></strong> (for Pseudospectrum Clustered GROUP), where multiple features now share the same ID. Features with the same <code>pcgroup</code> ID are <strong><em>hypothesized to be different adducts/isotopes of the same</em></strong> <strong>parent compound.</strong></p>
</section>
<section id="verifiable-proof-1" class="level4">
<h4 class="anchored" data-anchor-id="verifiable-proof-1"><strong>5. Verifiable â€œProofâ€</strong></h4>
<p>How can we prove that <code>CAMERA</code> did its job? We can extract its results table and inspect a specific <code>pseudospectrum</code> group.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 14. Verify the CAMERA Annotation ---</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co"># A) GET THE PEAK LIST WITH ANNOTATIONS</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># This peak list is a table with all features and the new annotation columns.</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>peaklist <span class="ot">&lt;-</span> <span class="fu">getPeaklist</span>(xa_annotated)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(peaklist) <span class="co"># Notice the new columns like 'isotopes' and 'pcgroup'</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="co"># B) VERIFY A SPECIFIC PSEUDOSPECTRUM</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's find a pcgroup that has several features in it.</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>pcgroup_summary <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">table</span>(peaklist<span class="sc">$</span>pcgroup))</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(pcgroup_summary) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"pcgroup_ID"</span>, <span class="st">"num_features"</span>)</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>interesting_pcgroup <span class="ot">&lt;-</span> pcgroup_summary <span class="sc">%&gt;%</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(num_features <span class="sc">&gt;</span> <span class="dv">2</span>) <span class="sc">%&gt;%</span> <span class="co"># Find a group with at least 3 members</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(num_features)) <span class="sc">%&gt;%</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice</span>(<span class="dv">1</span>) <span class="sc">%&gt;%</span> <span class="co"># Take the largest one as an example</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull</span>(pcgroup_ID)</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Now, let's look at all the features from this one group</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>example_group <span class="ot">&lt;-</span> peaklist <span class="sc">%&gt;%</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(pcgroup <span class="sc">==</span> interesting_pcgroup)</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">--- Verifying an example pseudospectrum group:"</span>, interesting_pcgroup, <span class="st">"---</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a><span class="co"># We only show the important columns for clarity</span></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(example_group[, <span class="fu">c</span>(<span class="st">"mz"</span>, <span class="st">"rt"</span>, <span class="st">"isotopes"</span>, <span class="st">"adduct"</span>, <span class="st">"pcgroup"</span>)])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li><p><strong>Action:</strong> Run this final block.</p></li>
<li><p><strong>Verification:</strong> The printed table is our proof. You will see a small table with several rows, but they all share the same <code>pcgroup ID.</code></p>
<ul>
<li><p><strong>Check the <code>rt</code> column:</strong> All the retention times <strong><em>should be nearly identical.</em></strong> This confirms they eluted together.</p></li>
<li><p><strong>Check the <code>mz</code> column:</strong> The m/z values will be <strong><em>different.</em></strong></p></li>
<li><p><strong>Check the adduct and isotopes columns:</strong> CAMERA will have made its best guess as to what each feature is. You might see one labeled [M+H]+, another [M+Na]+, and another identified as an isotope [M+1]. This is direct evidence that the algorithm successfully found and grouped these chemically related signals into a single, logical compound group.</p></li>
</ul></li>
</ul>
</section>
</section>
<section id="lesson-6-summary-status-check" class="level3">
<h3 class="anchored" data-anchor-id="lesson-6-summary-status-check"><strong>Lesson 6: Summary &amp; Status Check</strong></h3>
<ul>
<li><p><strong>Conceptually</strong>, we understand that our feature list is redundant due to isotopes and adducts, and that we must group these related features to get a list that more accurately represents unique compounds. We know that CAMERA does this by finding correlated features with specific mass differences.</p></li>
<li><p><strong>Practically</strong>, we have run the main CAMERA functions to create an annotated object.</p></li>
<li><p><strong>Crucially</strong>, we have followed the â€œTrust, but Verifyâ€ principle by extracting the peak list and inspecting a single â€œpseudospectrum,â€ confirming that the features within it have the expected properties (same RT, different m/z, plausible adduct/isotope assignments).</p></li>
</ul>
<p>We have now reached a major milestone. Our data is as clean and well-structured as it can be. We are finally ready to assemble the final data matrix for our statistical analysis.</p>
<hr>
</section>
<section id="lesson-7-building-the-final-data-matrix-normalization" class="level3">
<h3 class="anchored" data-anchor-id="lesson-7-building-the-final-data-matrix-normalization">Lesson 7: Building the Final Data Matrix &amp; NormalizationğŸ¦ª</h3>
<section id="goal-1" class="level4">
<h4 class="anchored" data-anchor-id="goal-1"><strong>1. Goal</strong></h4>
<p>Our goals for this lesson are twofold:</p>
<ol type="1">
<li><p><strong>To build the final data matrix:</strong> We will extract the <strong><em>quantitative information (peak intensities)</em></strong> from our processed object and <strong><em>create a table where the rows represent our unique compounds</em></strong> (using the <code>pcgroup</code> annotation from <code>CAMERA</code>) and the columns represent our 10 samples.</p></li>
<li><p><strong>To normalize the data:</strong> We will apply a normalization method to this matrix to correct for unavoidable technical variations between samples (e.g., slight differences in sample loading or instrument sensitivity over time). This ensures that the differences we see are biological, not technical.</p></li>
</ol>
</section>
<section id="underlying-logic-2" class="level4">
<h4 class="anchored" data-anchor-id="underlying-logic-2"><strong>2. Underlying Logic</strong></h4>
<ul>
<li><p><strong>Why build a new matrix?</strong> The <code>xcms</code> and <code>CAMERA</code> objects are complex and contain all the raw data. For statistics, we need a simple rows x columns matrix of numbers. Furthermore, we need to resolve the redundancy identified by CAMERA. If multiple features (e.g., [M+H]âº and [M+Na]âº) belong to the same <code>pcgroup</code>, we should <strong><em>represent them with a single row</em></strong> in our final matrix, typically by choosing the most intense and reliable feature.</p></li>
<li><p><strong>Why is normalization essential?</strong> Imagine you pipette 99 microliters of sample A but 101 microliters of sample B into the instrument vials. Every single metabolite in sample B would appear to be ~2% more abundant. This is purely technical variation. Normalization aims to correct for these kinds of global, systematic shifts. It assumes that most metabolites do not change between your samples, and it adjusts the intensity scales of each sample so that the bulk of the metabolites line up.</p></li>
<li><p><strong>A Common Normalization Method (PQN):</strong> <strong>Probabilistic Quotient Normalization (PQN(æ¦‚ç‡å•†å½’ä¸€åŒ–)</strong> is a robust and widely used method. Conceptually, it works like this:</p>
<ol type="1">
<li><p>It calculates a â€œreferenceâ€ spectrum (typically the median spectrum across all samples).</p></li>
<li><p>For each individual sample, it calculates the fold-change for every metabolite relative to this reference.</p></li>
<li><p>It finds the median of all these fold-changes for that sample. This median value is the most likely â€œscaling factorâ€ or technical error for that run.</p></li>
<li><p>It then divides all metabolite intensities in that sample by this scaling factor, bringing its overall intensity in line with all the other samples.</p></li>
</ol></li>
</ul>
</section>
<section id="practical-application-the-code-2" class="level4">
<h4 class="anchored" data-anchor-id="practical-application-the-code-2"><strong>3. Practical Application: The Code</strong></h4>
<p>This is the end of our <code>01_xcms_processing.R</code> script.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 15. Build and Normalize the Final Data Matrix ---</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="co"># This code continues in our '01_xcms_processing.R' script.</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co"># We will continue to work with the 'peaklist' data frame from CAMERA.</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Create a unique identifier for each compound (pcgroup)</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co"># We will select the most intense feature to represent each pcgroup.</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co"># First, get the intensity data for each feature across all samples.</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>intensity_matrix <span class="ot">&lt;-</span> <span class="fu">groupval</span>(xa_annotated, <span class="at">value =</span> <span class="st">"into"</span>)</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the maximum intensity for each feature across all samples</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>max_intensity <span class="ot">&lt;-</span> <span class="fu">apply</span>(intensity_matrix, <span class="dv">1</span>, max)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Add this max intensity and a unique feature ID to our peaklist</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>peaklist_processed <span class="ot">&lt;-</span> peaklist <span class="sc">%&gt;%</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">feature_id =</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">n</span>(), <span class="at">max_int =</span> max_intensity)</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Now, for each pcgroup, find the feature with the highest max_int</span></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>representative_features <span class="ot">&lt;-</span> peaklist_processed <span class="sc">%&gt;%</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(pcgroup) <span class="sc">%&gt;%</span></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice_max</span>(<span class="at">order_by =</span> max_int, <span class="at">n =</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>()</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the final, filtered intensity matrix</span></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>final_matrix_raw <span class="ot">&lt;-</span> intensity_matrix[representative_features<span class="sc">$</span>feature_id, ]</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Assign meaningful row names (a combination of m/z and RT)</span></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(final_matrix_raw) <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">"M"</span>, <span class="fu">round</span>(representative_features<span class="sc">$</span>mz, <span class="dv">4</span>),</span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"T"</span>, <span class="fu">round</span>(representative_features<span class="sc">$</span>rt, <span class="dv">2</span>))</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's inspect our raw, pre-normalization matrix</span></span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(final_matrix_raw)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li><strong>Action:</strong> Run this block. You have now created a clean data matrix, <code>final_matrix_raw</code> ,where each row represents the single most intense feature from each <code>pseudospectrum group</code>. This is a huge step!</li>
</ul>
<p>Now, letâ€™s normalize this matrix.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Perform Normalization and Log Transformation</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co"># We'll write a simple function for PQN for clarity.</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>normalize_pqn <span class="ot">&lt;-</span> <span class="cf">function</span>(mat) {</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Calculate reference spectrum (median)</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>  ref_spec <span class="ot">&lt;-</span> <span class="fu">apply</span>(mat, <span class="dv">1</span>, median)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Calculate quotients for each sample</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>  quotients <span class="ot">&lt;-</span> mat <span class="sc">/</span> ref_spec</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Calculate median quotient for each sample</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>  median_quotients <span class="ot">&lt;-</span> <span class="fu">apply</span>(quotients, <span class="dv">2</span>, median)</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Divide each sample by its median quotient</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>  mat_normalized <span class="ot">&lt;-</span> <span class="fu">t</span>(<span class="fu">t</span>(mat) <span class="sc">/</span> median_quotients)</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(mat_normalized)</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply PQN normalization</span></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>matrix_normalized <span class="ot">&lt;-</span> <span class="fu">normalize_pqn</span>(final_matrix_raw)</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a><span class="co"># It's also good practice to handle zero values before log transformation</span></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a><span class="co"># We'll replace them with a very small non-zero value (e.g., half the minimum)</span></span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>min_val <span class="ot">&lt;-</span> <span class="fu">min</span>(matrix_normalized[matrix_normalized <span class="sc">&gt;</span> <span class="dv">0</span>])</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>matrix_normalized[matrix_normalized <span class="sc">==</span> <span class="dv">0</span>] <span class="ot">&lt;-</span> min_val <span class="sc">/</span> <span class="dv">2</span></span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Finally, perform a log2 transformation. This helps to stabilize variance</span></span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a><span class="co"># and make the data more suitable for statistical tests.</span></span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>matrix_log2 <span class="ot">&lt;-</span> <span class="fu">log2</span>(matrix_normalized)</span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's look at our final, analysis-ready matrix</span></span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(matrix_log2)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li><strong>Action:</strong> Run this block. You now have the final product of all our processing: <code>matrix_log2</code>. This is a fully processed, normalized, and log-transformed data matrix.</li>
</ul>
</section>
<section id="expected-outcome-2" class="level4">
<h4 class="anchored" data-anchor-id="expected-outcome-2"><strong>4. Expected Outcome</strong></h4>
<p>The <code>matrix_log2</code> object is a data frame or matrix where:</p>
<ul>
<li><p>Rows are unique compounds, named by their m/z and retention time.</p></li>
<li><p>Columns are our 10 samples.</p></li>
<li><p>The values are the log2-transformed, normalized intensities.</p></li>
<li><p>There are no missing values (NA).</p></li>
<li><p>The data is now directly comparable across all samples.</p></li>
</ul>
</section>
<section id="verifiable-proof-2" class="level4">
<h4 class="anchored" data-anchor-id="verifiable-proof-2"><strong>5. Verifiable â€œProofâ€</strong></h4>
<p>How can we prove that normalization worked? A <code>boxplot</code> is the perfect tool. Before normalization, we expect to see the median intensity (the black line in the middle of the box) vary between samples. After normalization, these medians should be almost perfectly aligned.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 16. Verify the Normalization ---</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="co"># We need to reshape the data for ggplot2</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Before Normalization</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>df_before <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(final_matrix_raw) <span class="sc">%&gt;%</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">feature =</span> <span class="fu">rownames</span>(.)) <span class="sc">%&gt;%</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="sc">-</span>feature, <span class="at">names_to =</span> <span class="st">"sample"</span>, <span class="at">values_to =</span> <span class="st">"intensity"</span>)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="co"># After Normalization (but before log transform for visual clarity)</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>df_after <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(matrix_normalized) <span class="sc">%&gt;%</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">feature =</span> <span class="fu">rownames</span>(.)) <span class="sc">%&gt;%</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="sc">-</span>feature, <span class="at">names_to =</span> <span class="st">"sample"</span>, <span class="at">values_to =</span> <span class="st">"intensity"</span>)</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the plots</span></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>plot_before <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(df_before, <span class="fu">aes</span>(<span class="at">x =</span> sample, <span class="at">y =</span> <span class="fu">log10</span>(intensity))) <span class="sc">+</span></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>() <span class="sc">+</span></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Before Normalization"</span>) <span class="sc">+</span></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.text.x =</span> <span class="fu">element_text</span>(<span class="at">angle =</span> <span class="dv">45</span>, <span class="at">hjust =</span> <span class="dv">1</span>))</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>plot_after <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(df_after, <span class="fu">aes</span>(<span class="at">x =</span> sample, <span class="at">y =</span> <span class="fu">log10</span>(intensity))) <span class="sc">+</span></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>() <span class="sc">+</span></span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"After PQN Normalization"</span>) <span class="sc">+</span></span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.text.x =</span> <span class="fu">element_text</span>(<span class="at">angle =</span> <span class="dv">45</span>, <span class="at">hjust =</span> <span class="dv">1</span>))</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a><span class="co"># We can use a package to arrange them side-by-side</span></span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>normalization_plot <span class="ot">&lt;-</span> plot_before <span class="sc">+</span> plot_after</span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the plot</span></span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(normalization_plot)</span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the plot</span></span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a><span class="fu">ggsave</span>(<span class="st">"figures/04_normalization_verification.png"</span>, normalization_plot, <span class="at">width =</span> <span class="dv">12</span>, <span class="at">height =</span> <span class="dv">6</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li><p><strong>Action:</strong> Run this final block.</p></li>
<li><p><strong>Verification:</strong> The side-by-side <code>boxplots</code> are our definitive proof.</p>
<ul>
<li><p><strong>The â€œBeforeâ€ plot</strong> will likely show that the boxes for each sample are at different heights, indicating different intensity distributions.</p></li>
<li><p><strong>The â€œAfterâ€ plot</strong> should show a dramatic improvement. The black median lines for all 10 boxes should be aligned at almost exactly the same level. This is the visual confirmation that our normalization has corrected for the systematic technical differences between the runs.</p></li>
</ul></li>
</ul>
</section>
</section>
<section id="lesson-7-summary-status-check" class="level3">
<h3 class="anchored" data-anchor-id="lesson-7-summary-status-check"><strong>Lesson 7: Summary &amp; Status Check</strong></h3>
<ul>
<li><p><strong>Conceptually</strong>, we understand the need to distill our complex feature list into a simple data matrix and the absolute necessity of normalizing this matrix to ensure biological comparability.</p></li>
<li><p><strong>Practically</strong>, we have selected a representative feature for each compound group, built our final data matrix, and applied PQN normalization and log2 transformation.</p></li>
<li><p><strong>Crucially</strong>, we have followed the â€œTrust, but Verifyâ€ principle by creating before-and-after boxplots that provide clear, visual proof of the success of our normalization step.</p></li>
</ul>
<hr>
</section>
</section>
<section id="part-3-the-payoff---statistical-analysis-and-biological-interpretation" class="level2">
<h2 class="anchored" data-anchor-id="part-3-the-payoff---statistical-analysis-and-biological-interpretation">ğŸ•Šï¸Part 3: The Payoff - Statistical Analysis and Biological InterpretationğŸ§¶</h2>
<hr>
<section id="lesson-8-univariateå•å˜é‡-and-multivariateå¤šå˜é‡-statistics" class="level3">
<h3 class="anchored" data-anchor-id="lesson-8-univariateå•å˜é‡-and-multivariateå¤šå˜é‡-statistics">Lesson 8: Univariate(å•å˜é‡) and Multivariate(å¤šå˜é‡) StatisticsğŸ¤—</h3>
<p><strong>Goal:</strong> To analyze our final data matrix <code>(matrix_log2)</code> to identify which <code>specific metabolites have significantly changed in abundance between the Control and Metformin-treated groups</code>. We will use two complementary statistical approaches.</p>
<section id="underlying-logic-3" class="level4">
<h4 class="anchored" data-anchor-id="underlying-logic-3"><strong>1. Underlying Logic</strong></h4>
<p>Our data matrix has many rows (thousands of metabolites) and is therefore â€œhigh-dimensional.â€ We canâ€™t just look at it and see the patterns. We need two types of statistical tools:</p>
<ol type="1">
<li><p><strong>Multivariate Analysis (The â€œForestâ€ View):</strong> This approach looks at all metabolites at once to find the dominant patterns of variation in the data. Its primary purpose is <strong>unsupervised clustering</strong>. It answers the question: â€œBased on their overall metabolic profile, do my samples naturally group together by their condition (Control vs.&nbsp;Metformin)?â€ This is a powerful, unbiased first look at our data and a critical QC step. The most common method for this is <strong>Principal Component Analysis (PCA)</strong>.</p>
<ul>
<li><p><strong>How PCA Works:</strong> PCA finds the â€œprincipal components,â€ which are new, artificial axes that capture the maximum amount of variation in the data. PC1 is the axis that explains the most variation, PC2 explains the second most, and so on. By plotting the samples on these new axes (a â€œscores plotâ€), we can see if the dominant source of variation in our experiment corresponds to our biological question.</p></li>
<li><p><strong><em>PCA (and other multivariate methods like PLS-DA) is for HOLISTIC PATTERN RECOGNITION AND QC.(æ•´ä½“è¯†åˆ«å’ŒQC).PCA do confirm the experiment worked.</em></strong></p></li>
</ul></li>
<li><p><strong>Univariate Analysis (The â€œTreesâ€ View):</strong> This approach looks at one metabolite at a time. For each and every row in our matrix, it performs a statistical test to ask: â€œIs the mean intensity of this metabolite in the Control group significantly different from its mean in the Metformin group?â€ This is how we find our list of individual â€œhits.â€</p>
<ul>
<li><strong>The Tool:</strong> We will use the same powerhouse package from our proteomics project: <strong><code>limma</code></strong>. It is perfect for this task because it handles the multiple testing problem effectively and is statistically more powerful than running thousands of individual t-tests. The output will be a p-value and a fold-change for every single metabolite.</li>
</ul></li>
</ol>
</section>
<section id="practical-application-the-code-3" class="level4">
<h4 class="anchored" data-anchor-id="practical-application-the-code-3"><strong>2. Practical Application: The Code</strong></h4>
<p>We will now create our final R script for this project.</p>
<ul>
<li><strong>Action:</strong> In RStudio, create a new script in your scripts folder <code>named 02_statistical_analysis.R.</code></li>
</ul>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --------------------------------------------------------------------------</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Script: 02_statistical_analysis.R</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Author: Your Name</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Date: 2025-09-03</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="co"># --------------------------------------------------------------------------</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(limma)      <span class="co"># For univariate analysis</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pheatmap)   <span class="co"># For plotting heatmaps</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)  <span class="co"># For arranging plots</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Load the Final Data Matrix ---</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="co"># In a real workflow, we would save our final matrix from the previous script</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a><span class="co"># and load it here.</span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a><span class="co"># e.g., save(matrix_log2, pdata, file = "data_processed/final_matrix.RData")</span></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a><span class="co"># load("data_processed/final_matrix.RData")</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a><span class="co"># For this continuous example, we will assume 'matrix_log2' and 'pdata' are in our environment.</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<pre><code># --- 1. Multivariate Analysis: Principal Component Analysis (PCA) ---

# PCA works on a matrix where samples are rows and features are columns,
# so we need to transpose our data matrix 't()'. We also remove any
# columns with zero variance, which can cause issues.
pca_input &lt;- t(matrix_log2)
pca_input &lt;- pca_input[, apply(pca_input, 2, var) &gt; 0]

# Run the PCA
pca_result &lt;- prcomp(pca_input, scale. = TRUE, center = TRUE)

# Extract the scores for the first two principal components
pca_scores &lt;- as.data.frame(pca_result$x) %&gt;%
  select(PC1, PC2)

# Combine the PCA scores with our experimental design info for plotting
pca_scores_with_meta &lt;- merge(pca_scores, pdata, by.x = "row.names", by.y = "sample_name")

# Calculate the percentage of variance explained by each PC
percent_variance &lt;- round(100 * pca_result$sdev^2 / sum(pca_result$sdev^2), 1)

# Create the PCA scores plot
pca_plot &lt;- ggplot(pca_scores_with_meta, aes(x = PC1, y = PC2, color = sample_group)) +
  geom_point(size = 4, alpha = 0.8) +
  labs(
    title = "PCA of Metabolomic Profiles",
    x = paste0("PC1 (", percent_variance[1], "% variance)"),
    y = paste0("PC2 (", percent_variance[2], "% variance)"),
    color = "Experimental Group"
  ) +
  theme_bw() +
  coord_fixed() # Ensure the scaling of axes is equal

# Display the plot
print(pca_plot)
ggsave("figures/05_pca_plot.png", pca_plot, width = 7, height = 6)</code></pre>
<ul>
<li><p><strong>Action:</strong> Run this block.</p></li>
<li><p><strong>Verification:</strong> The PCA plot is our proof. A successful experiment will show a <strong>clear separation</strong> between the blue dots (Control) and the orange dots (Metformin), likely along the PC1 axis. This provides powerful, unbiased evidence that the Metformin treatment had a significant and consistent effect on the overall metabolism of the cells. If the groups were all mixed together, it would suggest a failed experiment or no biological effect.</p></li>
</ul>
<p>This will be very familiar from our proteomics project.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 2. Univariate Analysis with limma ---</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co"># We use the exact same logic as in the proteomics workflow.</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the design matrix</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>design <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(<span class="sc">~</span> <span class="dv">0</span> <span class="sc">+</span> pdata<span class="sc">$</span>sample_group)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(design) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Control"</span>, <span class="st">"Metformin"</span>)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the contrast matrix</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>contrast_matrix <span class="ot">&lt;-</span> <span class="fu">makeContrasts</span>(</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">Metformin_vs_Control =</span> Metformin <span class="sc">-</span> Control,</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">levels =</span> design</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the linear model</span></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lmFit</span>(matrix_log2, design)</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> <span class="fu">contrasts.fit</span>(fit, contrast_matrix)</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>fit_bayes <span class="ot">&lt;-</span> <span class="fu">eBayes</span>(fit2)</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the final results table</span></span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>results_table <span class="ot">&lt;-</span> <span class="fu">topTable</span>(fit_bayes, <span class="at">number =</span> <span class="cn">Inf</span>, <span class="at">sort.by =</span> <span class="st">"P"</span>)</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's inspect the top results</span></span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(results_table)</span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 3. Visualization: Volcano Plot ---</span></span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a column for significance to the results table</span></span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a>results_table <span class="ot">&lt;-</span> results_table <span class="sc">%&gt;%</span></span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a>    <span class="at">significance =</span> <span class="fu">case_when</span>(</span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a>      logFC <span class="sc">&gt;</span> <span class="dv">1</span> <span class="sc">&amp;</span> adj.P.Val <span class="sc">&lt;</span> <span class="fl">0.05</span> <span class="sc">~</span> <span class="st">"Upregulated in Metformin"</span>,</span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a>      logFC <span class="sc">&lt;</span> <span class="sc">-</span><span class="dv">1</span> <span class="sc">&amp;</span> adj.P.Val <span class="sc">&lt;</span> <span class="fl">0.05</span> <span class="sc">~</span> <span class="st">"Downregulated in Metformin"</span>,</span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a>      <span class="cn">TRUE</span> <span class="sc">~</span> <span class="st">"Not Significant"</span></span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the volcano plot</span></span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a>volcano_plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(results_table, <span class="fu">aes</span>(<span class="at">x =</span> logFC, <span class="at">y =</span> <span class="sc">-</span><span class="fu">log10</span>(adj.P.Val), <span class="at">color =</span> significance)) <span class="sc">+</span></span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.6</span>, <span class="at">size =</span> <span class="fl">1.5</span>) <span class="sc">+</span></span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Upregulated in Metformin"</span> <span class="ot">=</span> <span class="st">"#d95f02"</span>, <span class="st">"Downregulated in Metformin"</span> <span class="ot">=</span> <span class="st">"#1b9e77"</span>, <span class="st">"Not Significant"</span> <span class="ot">=</span> <span class="st">"grey"</span>)) <span class="sc">+</span></span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Metformin vs. Control Treatment"</span>,</span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="st">"Differentially Abundant Metabolites"</span>,</span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"log2(Fold Change)"</span>,</span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"-log10(Adjusted p-value)"</span></span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb23-48"><a href="#cb23-48" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb23-49"><a href="#cb23-49" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="sc">-</span><span class="fu">log10</span>(<span class="fl">0.05</span>), <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb23-50"><a href="#cb23-50" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>), <span class="at">linetype =</span> <span class="st">"dashed"</span>)</span>
<span id="cb23-51"><a href="#cb23-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-52"><a href="#cb23-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the plot</span></span>
<span id="cb23-53"><a href="#cb23-53" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(volcano_plot)</span>
<span id="cb23-54"><a href="#cb23-54" aria-hidden="true" tabindex="-1"></a><span class="fu">ggsave</span>(<span class="st">"figures/06_volcano_plot.png"</span>, volcano_plot, <span class="at">width =</span> <span class="dv">8</span>, <span class="at">height =</span> <span class="dv">7</span>)</span>
<span id="cb23-55"><a href="#cb23-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-56"><a href="#cb23-56" aria-hidden="true" tabindex="-1"></a><span class="co"># Finally, get our list of significant "hits"</span></span>
<span id="cb23-57"><a href="#cb23-57" aria-hidden="true" tabindex="-1"></a>significant_hits <span class="ot">&lt;-</span> results_table <span class="sc">%&gt;%</span></span>
<span id="cb23-58"><a href="#cb23-58" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(significance <span class="sc">!=</span> <span class="st">"Not Significant"</span>)</span>
<span id="cb23-59"><a href="#cb23-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-60"><a href="#cb23-60" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">Number of significantly changed metabolite features:"</span>, <span class="fu">nrow</span>(significant_hits))</span>
<span id="cb23-61"><a href="#cb23-61" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">head</span>(significant_hits))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li><p><strong>Action:</strong> Run this block.</p></li>
<li><p><strong>Verification:</strong> The volcano plot is our proof. It visualizes the results of our thousands of statistical tests. The points in the top-left (downregulated) and top-right (upregulated) corners are our <strong>significant hits</strong>. The significant_hits data frame is the final, tangible output of this analysisâ€”a high-confidence list of the metabolite features that were most affected by the drug treatment.</p></li>
</ul>
</section>
</section>
<section id="lesson-8-summary-status-check" class="level3">
<h3 class="anchored" data-anchor-id="lesson-8-summary-status-check"><strong>Lesson 8: Summary &amp; Status Check</strong></h3>
<ul>
<li><p><strong>Conceptually</strong>, we understand the complementary nature of multivariate (PCA) and univariate (limma) analysis. PCA gives us the â€œforestâ€ view, confirming our experiment worked, while limma gives us the â€œtreesâ€ view, identifying the individual significant metabolites.</p></li>
<li><p><strong>Practically</strong>, we have successfully run a PCA and a full limma pipeline on our processed metabolomics data.</p></li>
<li><p><strong>Crucially</strong>, we have followed the â€œTrust, but Verifyâ€ principle by generating two key plots:</p>
<ol type="1">
<li><p>The <strong>PCA plot</strong> verifies that our experimental groups are globally different.</p></li>
<li><p>The <strong>Volcano plot</strong> verifies our univariate analysis, clearly displaying the significant hits according to our chosen statistical thresholds.</p></li>
</ol></li>
</ul>
<p>We are now on the verge of the final discovery. We have a list of significant â€œfeaturesâ€ (e.g., â€œM175.0234T3.45â€). The next, and most challenging, lesson is to try and figure out what these features actually are.</p>
<hr>
</section>
</section>
<section id="lesson-9-metabolite-identification-and-annotation-the-deeper-dive" class="level2">
<h2 class="anchored" data-anchor-id="lesson-9-metabolite-identification-and-annotation-the-deeper-dive">Lesson 9: Metabolite Identification and Annotation (The Deeper Dive)ğŸ¤ </h2>
<section id="goal-2" class="level4">
<h4 class="anchored" data-anchor-id="goal-2"><strong>1. Goal</strong></h4>
<p><strong><em>Our goal is to take the list of significant features from our statistical analysis and assign a putative(å‡å®šçš„) chemical identity to them. This involves <code>querying online databases</code> with the highly accurate mass of our features to find potential matches. We must also understand the different levels of confidence in these identifications.</em></strong></p>
</section>
<section id="underlying-logic-4" class="level4">
<h4 class="anchored"><strong>2. Underlying Logic</strong></h4>
<ul>
<li><p><strong>The Challenge:</strong> <strong><em>Unlike proteomics, where peptides are made from a simple 20-letter amino acid alphabet,</em></strong> the chemical space of metabolites is astronomically <strong><em>vast and diverse</em></strong>. <strong><em>There is no simple â€œsearch engineâ€ that can definitively identify a metabolite from its mass alone.</em></strong></p></li>
<li><p><strong>The Primary Clue: Accurate Mass.</strong> Our most powerful piece of information is the <strong><em>very precise mass-to-charge ratio (m/z) that we measured.</em></strong> For a feature like â€œM175.0234T3.45â€, the key is the mass: 175.0234. We can search <strong><em>databases</em></strong> to ask, â€œ<strong><em>What known biological molecules have a mass that is extremely close to this value?â€œ</em></strong></p></li>
<li><p><strong>The Problem of Adducts:</strong> Remember <strong><code>CAMERA</code></strong>? It told us that a feature might be the protonated form [M+H]âº, or a sodium adduct [M+Na]âº, etc. When we search a database, we must search for the mass of the <strong>neutral molecule (M)(ä¸­æ€§åˆ†å­)</strong>. Therefore, before searching, we must first â€œde-adductâ€ our measured m/z.</p>
<ul>
<li><p>If we believe our feature 175.0234 is the [M+H]âº form, the <strong><em>neutral mass is 175.0234 - (mass of a proton) = 174.0156.</em></strong></p></li>
<li><p>If we believe it is the [M+Na]âº form, the neutral mass is 175.0234 - (mass of a sodium ion) = 152.0368.<br>
This is why the <strong><code>CAMERA</code></strong> annotation step was so important.</p>
<p>CAMERA (Collection of Algorithms for MEtabolite pRofile Annotation) doesnâ€™t â€œknowâ€ in the strict senseâ€”it infers based on <strong>mass differences</strong>, <strong>intensity patterns</strong>, and <strong>co-elution behavior</strong>. Hereâ€™s how:</p>
<h4 id="co-elution-and-retention-time" class="anchored">1. <strong>Co-elution and Retention Time</strong></h4>
<ul>
<li><p>CAMERA starts by clustering features that elute at nearly the same retention time.</p></li>
<li><p>The assumption: if two ions appear at the same time, they likely come from the same compound.</p></li>
</ul>
<h4 id="mass-differences-matching-known-adducts" class="anchored">2. <strong>Mass Differences Matching Known Adducts</strong></h4>
<ul>
<li><p>It uses a predefined list of adducts (e.g., [M+H]âº, [M+Na]âº, [M+K]âº) and their exact mass shifts.</p></li>
<li><p>If two features differ by the mass of a sodium ion minus a proton (~21.9819 Da)(ä¸¤ä¸ªç‰¹æ€§ç›¸å‡å¾—åˆ°ä¸€ä¸ªè´¨å­), and they co-elute, CAMERA flags them as possible [M+H]âº and [M+Na]âº forms of the same molecule.</p></li>
</ul>
<h4 id="isotope-patterns" class="anchored">3. <strong>Isotope Patterns</strong></h4>
<ul>
<li><p>It checks for isotopic spacing (e.g., 1.00335 Da for C13) and intensity ratios.</p></li>
<li><p>This helps distinguish monoisotopic peaks from their heavier isotopologues.</p></li>
</ul>
<h4 id="intensity-ratios-and-charge-states" class="anchored">4. <strong>Intensity Ratios and Charge States</strong></h4>
<ul>
<li><p>Adducts often have characteristic intensity patterns. For example, [M+H]âº is usually more abundant than [M+Na]âº.</p></li>
<li><p>CAMERA uses these patterns to refine its grouping.</p></li>
</ul>
<h3 id="why-de-adducting-is-necessary" class="anchored" data-anchor-id="underlying-logic-4">ğŸ§  Why â€œDe-adductingâ€ Is Necessary</h3>
<p>When you search a database like HMDB or METLIN, they expect the <strong>neutral mass (M)</strong>, not the m/z of the adduct. So CAMERA helps you:</p>
<ul>
<li><p>Group all adducts and isotopes of a compound.</p></li>
<li><p>Infer the neutral mass by subtracting the adduct mass.</p></li>
<li><p>Output a cleaned list of neutral masses for annotation.</p></li>
</ul>
<h3 id="example" class="anchored">ğŸ§° Example</h3>
<p>Letâ€™s say you detect three features:</p>
<ul>
<li><p>m/z 180.065 (RT 5.2 min)</p></li>
<li><p>m/z 201.045 (RT 5.2 min)</p></li>
<li><p>m/z 181.068 (RT 5.2 min)</p></li>
</ul>
<p>CAMERA sees:</p>
<ul>
<li><p>180.065 could be [M+H]âº</p></li>
<li><p>201.045 is ~21.98 Da higher â†’ likely [M+Na]âº</p></li>
<li><p>181.068 is ~1.003 Da higher â†’ likely C13 isotope of [M+H]âº</p></li>
</ul>
<p>It bundles them, assigns a neutral mass of ~179.057, and tags the adducts accordingly.</p></li>
</ul></li>
<li><p><strong>Levels of Identification Confidence:</strong> The Metabolomics Standards Initiative (MSI) has defined a clear, tiered system for reporting identifications. It is crucial to be honest about our level of confidence.</p>
<ul>
<li><p><strong>Level 4: Unidentified Compound.</strong> This is our current state: a feature with a mass and RT, but no name.</p></li>
<li><p><strong>Level 3: Putatively Characterized Compound Class.</strong> (e.g., based on spectral data, we might guess itâ€™s a type of sugar).</p></li>
<li><p><strong>Level 2: Putatively Annotated Compound.</strong> This is our goal for today. We get a match based on accurate mass from a database (e.g., M174.0156 is a perfect match for the neutral mass of Arginine). This is a strong hypothesis, but not a confirmation.</p></li>
<li><p><strong>Level 1: Confidently Identified Compound.</strong> This is the gold standard. To achieve this, you must match <strong>two</strong> orthogonal properties(æ­£äº¤å±æ€§), most commonly:</p>
<ol type="1">
<li><p>Accurate mass and retention time against a <strong><em>pure, purchased chemical standard run on the exact same machine.</em></strong></p></li>
<li><p>Accurate mass and its MS/MS fragmentation spectrum against a library spectrum from a pure standard.</p></li>
</ol></li>
</ul></li>
</ul>
<p>For our untargeted bioinformatics analysis, we will be operating at <strong>Level 2</strong>. We are generating high-quality hypotheses.</p>
</section>
<section id="practical-application-the-code-4" class="level4">
<h4 class="anchored" data-anchor-id="practical-application-the-code-4"><strong>3. Practical Application: The Code</strong></h4>
<p>For this task, we will use a fantastic R package that interfaces directly with many online <code>metabolomics</code> databases: MetaboAnalystR.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install the MetaboAnalystR package (it has many dependencies)</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="co"># This might take a while.</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">require</span>(<span class="st">"MetaboAnalystR"</span>)){</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">install.packages</span>(<span class="st">"remotes"</span>)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>  remotes<span class="sc">::</span><span class="fu">install_github</span>(<span class="st">"xia-lab/MetaboAnalystR"</span>, <span class="at">build =</span> <span class="cn">TRUE</span>)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Add this to our '02_statistical_analysis.R' script</span></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MetaboAnalystR)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li><strong>Action:</strong> Install <code>MetaboAnalystR</code> . Itâ€™s a large and powerful package. Then, add it to the library section of your <code>02_statistical_analysis.R script.</code></li>
</ul>
<p>Now, letâ€™s take our list of significant hits and prepare them for searching.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 4. Metabolite Annotation and Identification ---</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's work with our 'significant_hits' data frame.</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="co"># It has row names like "M175.0234T3.45"</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="co"># We need to extract the m/z values from these names.</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>mz_values <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">str_extract</span>(<span class="fu">rownames</span>(significant_hits), <span class="st">"(?&lt;=M)</span><span class="sc">\\</span><span class="st">d+</span><span class="sc">\\</span><span class="st">.</span><span class="sc">\\</span><span class="st">d+"</span>))</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a query list for MetaboAnalystR. It needs a data frame</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="co"># with columns for m/z, p-value, and fold-change.</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>query_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">mz =</span> mz_values,</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">p.value =</span> significant_hits<span class="sc">$</span>adj.P.Val,</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">fc =</span> <span class="dv">2</span><span class="sc">^</span>significant_hits<span class="sc">$</span>logFC, <span class="co"># Convert log2FC back to a regular fold change</span></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">row.names =</span> <span class="fu">rownames</span>(significant_hits)</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Perform the Database Search ---</span></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the analysis object</span></span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>mSet <span class="ot">&lt;-</span> <span class="fu">InitDataObjects</span>(<span class="st">"mass_all"</span>, <span class="st">"mummichog"</span>, <span class="cn">FALSE</span>)</span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the parameters for the search. We need to tell it about our instrument.</span></span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's assume our data is from an Orbitrap in positive ion mode.</span></span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>mSet <span class="ot">&lt;-</span> <span class="fu">SetPeakFormat</span>(mSet, <span class="st">"mpr"</span>) <span class="co"># mpr = m/z, p-value, retention time (we don't have RT here)</span></span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>mSet <span class="ot">&lt;-</span> <span class="fu">UpdateInstrumentParameters</span>(mSet, <span class="fl">5.0</span>, <span class="st">"orbi"</span>, <span class="st">"positive"</span>, <span class="st">"uv"</span>) <span class="co"># 5.0 ppm tolerance</span></span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Load our query data into the object</span></span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a>mSet <span class="ot">&lt;-</span> <span class="fu">Read.PeakListData</span>(mSet, query_df)</span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform the peak annotation. This function will de-adduct and search.</span></span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a><span class="co"># It queries a comprehensive database based on KEGG, HMDB, etc.</span></span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a>mSet <span class="ot">&lt;-</span> <span class="fu">PerformPSEA</span>(mSet, <span class="st">"hsa"</span>, <span class="st">"current"</span>, <span class="dv">100</span>) <span class="co"># hsa = homo sapiens</span></span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the results table</span></span>
<span id="cb25-35"><a href="#cb25-35" aria-hidden="true" tabindex="-1"></a>annotation_results <span class="ot">&lt;-</span> mSet<span class="sc">$</span>dataSet<span class="sc">$</span>mummi.res</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Run this block. <code>ThePerformPSEA`</code>function is doing the heavy lifting. It connects to the <code>MetaboAnalyst server,</code> uploads your list of m/z values, performs the de-adduction, searches against a comprehensive human metabolome database within the 5 ppm mass tolerance, and downloads the results.</p>
</section>
<section id="expected-outcome-3" class="level4">
<h4 class="anchored" data-anchor-id="expected-outcome-3"><strong>4. Expected Outcome</strong></h4>
<p>The <code>annotation_results</code> data frame is our table of putative identifications. It will have columns like: <code>mass_matched</code>: The m/z from our query list.</p>
<p><code>name</code>: The common name of the matched metabolite (e.g., â€œL-Arginineâ€).</p>
<p><code>kegg_id</code>, <code>hmdb_id</code>: The database IDs for the match.</p>
<p><code>adduct_type</code>: The adduct that <code>MetaboAnalystR</code> assumed to get the match (e.g., â€œ[M+H]+â€).</p>
<p><code>pathway_matched</code>: Which metabolic pathways the identified metabolite belongs to.</p>
</section>
<section id="verifiable-proof-3" class="level4">
<h4 class="anchored" data-anchor-id="verifiable-proof-3"><strong>5. Verifiable â€œProofâ€</strong></h4>
<p>How can we trust these annotations? We can perform a manual check on one of the top hits.</p>
<p><strong>Action:</strong> Inspect the output table. Perform the manual check described in the comments for one of the top hits. This process of manually confirming the math for a top hit is a fundamental skill and a crucial verification step.</p>
<pre><code>
# Let's look at the top of our annotation results table
# We will show only the most important columns for clarity.
print(head(annotation_results[, c("mass_matched", "name", "adduct_type", "pathway_matched")]))

# --- Manual Verification of the Top Hit ---
top_hit &lt;- annotation_results[1, ]
our_mz &lt;- as.numeric(top_hit$mass_matched)
putative_id &lt;- top_hit$name
assumed_adduct &lt;- top_hit$adduct_type</code></pre>
<p>We will now go to an external database, like the Human Metabolome Database (HMDB) and manually verify this. Letâ€™s say the top hit is â€œL-Glutamine(è°·æ°¨é…°èƒº)â€.</p>
<ol type="1">
<li><p>Google â€œHMDB L-Glutamineâ€.</p></li>
<li><p>On the HMDB page, find the exact monoisotopic mass of the neutral molecule(å•åŒä½ç´ è´¨é‡æ•°). (For L-Glutamine, this is 146.0691 g/mol).</p></li>
<li><p>Now, letâ€™s calculate what the mass of the [M+H]+ adduct should be. Mass of a proton is ~1.007276 Da. Expected [M+H]+ mass = 146.0691 + 1.007276 = 147.0764 Da.</p></li>
<li><p>Compare this to our measured m/z. Letâ€™s say our feature was M147.0763.</p></li>
</ol>
<p>This manual calculation, confirming that our measured mass is within a few ppm of the theoretical mass for the adduct suggested by the software, is our â€œTrust, but Verifyâ€ step. It gives us confidence that the algorithm is working correctly.</p>
</section>
<section id="lesson-9-summary-status-check" class="level3">
<h3 class="anchored" data-anchor-id="lesson-9-summary-status-check"><strong>Lesson 9: Summary &amp; Status Check</strong></h3>
<ul>
<li><strong>Conceptually</strong>, we understand the immense challenge of metabolite identification and the crucial difference between a â€œputative annotationâ€ (Level 2) and a â€œconfident identificationâ€ (Level 1). We know that our primary tool is matching the accurate neutral mass against online databases.</li>
<li><strong>Practically</strong>, we have used the powerful <code>MetaboAnalystR</code> package to perform an automated database search on our list of significant features.</li>
<li><strong>Crucially</strong>, we have followed the â€œTrust, but Verifyâ€ principle by defining a clear procedure for manually cross-referencing a top hit against an external database like HMDB to confirm the mass calculation.</li>
</ul>
<p>We have now transformed our anonymous list of features into a list of meaningful, named metabolites. We are finally ready for the grand finale: taking these named metabolites and discovering which biological pathways are being altered by our drug treatment.</p>
<hr>
</section>
<section id="lesson-10-pathway-and-enrichment-analysis" class="level3">
<h3 class="anchored" data-anchor-id="lesson-10-pathway-and-enrichment-analysis">Lesson 10: Pathway and Enrichment AnalysisğŸª‚</h3>
<p><strong>Goal:</strong> To take our list of putatively identified, significantly changed metabolites and determine if they are statistically over-represented <strong><em>in any known metabolic pathways</em></strong>. This will provide the ultimate biological story, explaining how Metformin is affecting the cellâ€™s metabolism.</p>
<section id="underlying-logic-5" class="level4">
<h4 class="anchored" data-anchor-id="underlying-logic-5"><strong>1. Underlying Logic</strong></h4>
<p>This concept is identical to the enrichment analysis we performed in proteomics.</p>
<ul>
<li><p><strong>The Problem:</strong> We might have a list of 50 significant metabolites. Simply reading the list (e.g., â€œGlutamine is down, Citrate is up, Succinate is upâ€¦â€) doesnâ€™t immediately tell us the story.</p></li>
<li><p><strong>The Question:</strong> Are these changes random, or <strong><em>are they concentrated in a specific, coordinated biological process?</em></strong></p></li>
<li><p><strong>The Method (Metabolite Set Enrichment Analysis - MSEA(ä»£è°¢ç‰©é›†å¯Œé›†åˆ†æ)):</strong> We use a statistical test (the <strong><code>hypergeometric test</code></strong>, just like before) to check if our list of 50 â€œhitsâ€ contains a surprisingly high number of metabolites belonging to a predefined â€œMetabolite Setâ€ (like the â€œCitric Acid (TCA) Cycleâ€ pathway). If the probability of seeing that many hits in that pathway by random chance is very low (i.e., a small p-value), <strong><em>we can conclude that the pathway is â€œsignificantly enrichedâ€ or â€œsignificantly impacted.â€</em></strong></p></li>
</ul>
<p>The <code>MetaboAnalystR</code> package we used in the last lesson has this functionality built-in, making it a seamless next step.</p>
</section>
</section>
<section id="practical-application-the-code-in-chunks" class="level3">
<h3 class="anchored" data-anchor-id="practical-application-the-code-in-chunks"><strong>Practical Application: The Code in Chunks</strong></h3>
<p>We will continue in our <code>02_statistical_analysis.R</code> script.</p>
<section id="chunk-1-preparing-the-data-for-enrichment" class="level4">
<h4 class="anchored" data-anchor-id="chunk-1-preparing-the-data-for-enrichment"><strong>Chunk 1: Preparing the Data for Enrichment</strong></h4>
<p><strong>Explanation:</strong> The enrichment analysis function doesnâ€™t need our full data table. It just needs a simple list of the compound names that we found were significant. We will extract these names from the annotation results we got in the previous lesson. We also need to be careful to select the correct set of names if our annotation found multiple hits for one mass.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 6. Pathway and Enrichment Analysis ---</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="co"># We will use the 'mSet' object from the previous lesson, as it already</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="co"># contains our query and the annotation results.</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="co"># The pathway analysis function in MetaboAnalystR uses the results already</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="co"># stored in the mSet object after we ran PerformPSEA(). It will automatically</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="co"># use the putatively identified compounds for the enrichment test.</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="co"># First, we need to specify which metabolite sets we want to test against.</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="co"># We will use the comprehensive pathway library from KEGG.</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>mSet <span class="ot">&lt;-</span> <span class="fu">SetKEGG.PathLib</span>(mSet, <span class="st">"hsa"</span>, <span class="st">"current"</span>) <span class="co"># hsa = Homo sapiens</span></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Now, we are ready to run the enrichment analysis.</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li><strong>Action:</strong> Add this small setup chunk to your script and run it. We have now told <code>MetaboAnalystR</code> that we <strong><em>want to test our data against the library of all known human KEGG pathways.</em></strong></li>
</ul>
</section>
<section id="chunk-2-running-the-enrichment-analysis" class="level4">
<h4 class="anchored" data-anchor-id="chunk-2-running-the-enrichment-analysis"><strong>Chunk 2: Running the Enrichment Analysis</strong></h4>
<p><strong>Explanation:</strong> Now we call the main function to perform the analysis. This function will take the list of all metabolites that were successfully annotated in our query, cross-reference them against all the KEGG pathways, and perform the <code>hypergeometric test</code> for each pathway.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the Metabolite Set Enrichment Analysis (MSEA)</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>mSet <span class="ot">&lt;-</span> <span class="fu">PerformPathEnrich</span>(mSet, <span class="st">"globaltest"</span>, <span class="st">"pathway"</span>) <span class="co"># Using the 'globaltest' algorithm</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="co"># The results are now stored within our mSet object.</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li><strong>Action:</strong> Run this command. <code>MetaboAnalystR</code> is now performing the statistical tests.</li>
</ul>
</section>
<section id="chunk-3-extracting-and-viewing-the-results" class="level4">
<h4 class="anchored" data-anchor-id="chunk-3-extracting-and-viewing-the-results"><strong>Chunk 3: Extracting and Viewing the Results</strong></h4>
<p><strong>Explanation:</strong> The results are stored in a table inside our <code>mSet</code> object. We need to extract this table to view it. The table will be ranked by significance, showing us the most impacted pathways at the top.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the results table from the mSet object</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>enrichment_results <span class="ot">&lt;-</span> mSet<span class="sc">$</span>analSet<span class="sc">$</span>path.result</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's view the most important columns of the results table</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="co"># - 'Total' is the total number of metabolites in the pathway.</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="co"># - 'Hits' is how many of our significant metabolites are in that pathway.</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="co"># - 'P.Value' is the raw p-value from the hypergeometric test.</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="co"># - 'FDR' is the false discovery rate (adjusted p-value), which is most important.</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">head</span>(enrichment_results[, <span class="fu">c</span>(<span class="st">"Total"</span>, <span class="st">"Hits"</span>, <span class="st">"P.Value"</span>, <span class="st">"FDR"</span>)]))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li><strong>Action:</strong> Run this chunk. The table printed in your console is the main result. You can now read the row names to see which pathways were most significantly altered. <strong><em>For our Metformin project, we would expect to see pathways like â€œCentral carbon metabolismâ€ or â€œAmino acid metabolism.â€</em></strong></li>
</ul>
</section>
<section id="chunk-4-visualizing-the-enrichment-results" class="level4">
<h4 class="anchored" data-anchor-id="chunk-4-visualizing-the-enrichment-results"><strong>Chunk 4: Visualizing the Enrichment Results</strong></h4>
<p><strong>Explanation:</strong> A table of numbers is good, but a plot is much better for communication and interpretation. We will create a bar chart that <strong><em>shows the top 15 most significant pathways</em></strong>, ranked by their p-value. This provides an immediate, intuitive view of the most important biological findings.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the enrichment results</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="co"># This function is built into MetaboAnalystR for easy visualization.</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="fu">PlotPathSummary</span>(mSet, </span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">fig.name =</span> <span class="st">"figures/08_pathway_enrichment_plot.png"</span>,</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>              <span class="at">width =</span> <span class="dv">8</span>, </span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>              <span class="at">height =</span> <span class="dv">7</span>, </span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>              <span class="at">dpi =</span> <span class="dv">300</span>)</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a><span class="co"># The plot will be saved to the 'figures' folder.</span></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a><span class="co"># It shows the pathways on the y-axis and the -log10(p-value) on the x-axis.</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Bigger bars mean more significant enrichment. The dot color/size indicates</span></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a><span class="co"># the impact or number of hits.</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li><p><strong>Action:</strong> Run this final command. Go to your figures folder and open the new <code>PNG</code> file.</p></li>
<li><p><strong>Verification:</strong> The plot itself is the proof. <strong><em>You have a clear, publication-ready figure that summarizes the entire biological story of your experiment.</em></strong> It visually confirms the findings from the results table. For example, if â€œCitric Acid (TCA) Cycleâ€ has the biggest bar, you have strong evidence that Metforminâ€™s primary effect is on the cellâ€™s central energy production.</p></li>
</ul>
</section>
</section>
<section id="grand-conclusion-of-the-entire-metabolomics-project" class="level3">
<h3 class="anchored" data-anchor-id="grand-conclusion-of-the-entire-metabolomics-project"><strong>Grand Conclusion of the Entire Metabolomics Project</strong></h3>
<p>Letâ€™s synthesize the story from this final lesson.</p>
<ol type="1">
<li><p><strong>From Hits to Names:</strong> In Lesson 9, we turned our significant feature list (e.g., â€œM117.0189â€¦â€) into a list of putative metabolite names (e.g., â€œSuccinic acidâ€).</p></li>
<li><p><strong>From Names to Pathways:</strong> In this lesson, we took that list of names and discovered they werenâ€™t random. Our enrichment analysis showed, for instance, that â€œSuccinic acid,â€ â€œCitric acid,â€ â€œMalic acid,â€ and â€œFumaric acidâ€ were all significantly upregulated.</p></li>
<li><p><strong>The Biological Story:</strong> The enrichment plot tells us that these metabolites are not just a random collection; they are all key players in the <strong>â€œCitric Acid (TCA) Cycle.â€</strong></p></li>
</ol>
<p><strong>The Final Hypothesis:</strong><br>
â€œOur untargeted metabolomics analysis reveals that Metformin treatment significantly perturbs(æ‰°ä¹±) central carbon metabolism in <code>HepG2</code> cells. We observed a statistically significant enrichment of the Citric Acid (TCA) Cycle pathway, driven by the coordinated upregulation of multiple key cycle intermediates. This suggests that Metforminâ€™s anti-cancer effects in this model may be mediated by altering the cellâ€™s fundamental energy production pathways.â€</p>
</section>
</section>
</section>
     </main>
<!-- /main column -->  <script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "î§‹";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>  </div> <!-- /content --> 
  
</body></html>